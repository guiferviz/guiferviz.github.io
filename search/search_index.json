{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"window.addEventListener(\"load\", function () { var sketch = function( p ) { // Taken from https://p5js.org/es/reference/#/p5/createShader let varying = ` precision highp float; varying vec2 vPos; `; let vs = varying + ` attribute vec3 aPosition; void main() { vPos = (gl_Position = vec4(aPosition,1.0)).xy; } `; let fs = varying + ` uniform vec2 p; uniform float r; const int I = 150; void main() { vec2 c = p + vPos * r, z = c; float n = 0.0; for (int i = I; i > 0; i --) { if (z.x*z.x+z.y*z.y > 4.0) { n = float(i)/float(I); break; } z = vec2(z.x*z.x-z.y*z.y, 2.0*z.x*z.y) + c; } gl_FragColor = vec4( 0.5-cos(n*17.0)/2.0, 0.5-cos(n*13.0)/2.0, 0.5-cos(n*19.0)/2.0, 1.0 ); } `; let shader, logo, shaderTexture; let width = 1080/2; let height = 720/3; p.preload = function () { logo = p.loadImage(\"assets/images/logo_white.png\"); }; p.setup = function () { p.createCanvas(width, height, p.WEBGL); p.smooth(); shaderTexture = p.createGraphics(width, height, p.WEBGL); shader = shaderTexture.createShader(vs, fs); shaderTexture.shader(shader); shaderTexture.noStroke(); shader.setUniform(\"p\", [-0.74364388703, 0.13182590421]); }; p.draw = function () { let r = 2.5 * p.exp(-6.5 * (1 + p.sin(p.millis() / 3000))); shader.setUniform(\"r\", r); shaderTexture.quad(-1, -1, 1, -1, 1, 1, -1, 1); p.push(); p.texture(shaderTexture); p.rect(-width/2, -height/2, width, height); p.pop(); p.push(); p.scale(0.3*2.5/r); p.image(logo, width*0.1, 0); p.pop(); }; }; var myp5 = new p5(sketch, \"my-container\"); });","title":"Home"},{"location":"about/","text":"Este blog va dirigido a... Este blog va dirigido a aquellas personas que disfrutan m\u00e1s monitorizando el entreno de una red neuronal que viendo un partido de su deporte favorito. Este blog va dirigido a aquellas personas que acompa\u00f1an su desayuno dominical con la lectura de un nuevo paper en lugar de con la serie que est\u00e9n echando en ese momento. Va dirigido a aquellas personas que no se conforman con usar programas o librer\u00edas como si de cajas negras se trataran, va dirigido a quienes quieren saber qu\u00e9 es lo que realmente pasa dentro de esa caja. Va dirigido a aquellas personas que aman los algoritmos y las matem\u00e1ticas. En definitiva, este blog va dirigido a gente como yo. \u00bfQui\u00e9n soy yo? Aunque creo que con la secci\u00f3n superior ya te puedes hacer una buena idea de c\u00f3mo soy, es comprensible que quieras una descripci\u00f3n algo m\u00e1s formal de este blog y de su autor. Me llamo Guillermo y estudi\u00e9 el grado de Ingenier\u00eda Inform\u00e1tica en la Universidad de Alicante (Espa\u00f1a). Lo finaliz\u00e9 en 2016 y desde entonces mi vida profesional se resume en 3 a\u00f1os de trabajo en SolidQ , una consultora partners de Microsoft especializada en el tratamiento de los datos en todas sus variantes. Fue all\u00ed donde puse en pr\u00e1ctica mis conocimiento te\u00f3ricos de Machine Learning (ML) y donde aprend\u00ed a tratar con clientes. Despu\u00e9s de mis 3 a\u00f1os en SolidQ, a finales del verano del 2019, decid\u00ed tomarme un descanso para ver mundo y disfrutar del humilde placer del estudio de la inform\u00e1tica (ML y t\u00e9cnicas algor\u00edtmicas). Actualmente a\u00fan me encuentro disfrutando de este break y viajando sin rumbo fijo, viviendo al d\u00eda e improvisando el futuro cercano. No soy muy amigo de las redes sociales (con las redes neuronales ya tengo bastantes redes \ud83d\ude1c), pero de vez en cuando me dejo caer por alguna de ellas y... \u00a1hasta respondo a algunos mensajes! Cotill\u00e9ame los perfiles o s\u00edgueme para saber algo m\u00e1s de mi y enterarte de las futuras novedades de este blog. \u00bfPor qu\u00e9 este blog? La cantidad de experimentos y c\u00f3digo que he escrito en mi ordenador es muy grande, pero pocos de ellos han visto la luz. Es una pena que todo ese contenido y todos los conocimientos que he ido adquiriendo despu\u00e9s de a\u00f1os de estudio se queden solo a mi disposici\u00f3n. Este blog pretende recopilar muchos de esos contenidos para que cualquiera con una conexi\u00f3n a Internet pueda sacarles partido. Tambi\u00e9n, adem\u00e1s de ayudar a otra gente, mis art\u00edculos pretenden ayudar al Guillermo del futuro. No todo lo aprendido se retiene eternamente, as\u00ed que me vendr\u00e1 bien refrescar lo aprendido leyendo mis propios art\u00edculos. Creedme, no hay mejores explicaciones para uno mismo que las que uno mismo escribi\u00f3. La idea de crear un blog como \u00e9ste viene de muy atr\u00e1s, pero la falta de tiempo y mi perfeccionismo no me dej\u00f3 empezarlo... hasta hoy. Es aqu\u00ed donde me veo obligado a citar a Reid Hoffman. \"Si no te averg\u00fcenza la primera versi\u00f3n de tu producto, lo lanzaste muy tarde\" -- Reid Hoffman, cofundador de LinkedIn Prometi\u00e9ndome a m\u00ed mismo encontrar un punto de perfeccionismo que me permita empezar a publicar art\u00edculos sin perder demasiada calidad, doy a luz a este blog. Dedicatoria Me gustar\u00eda agradecer p\u00fablicamente a todos aquellos que han hecho posible que me haya iniciado en el mundo de la inform\u00e1tica. Son ya muchos a\u00f1os los que llevo estudiando de forma autodidacta a trav\u00e9s de Internet, as\u00ed que me gustar\u00eda aprovechar bien esta dedicatoria agradeciendo a cada una de las personas que han compartido sus conocimientos de forma desinteresada en la red. Les agradezco de todo coraz\u00f3n sus aportes, aportes que entre la gran cantidad de datos que hay en Internet son insignificantes, pero que para m\u00ed han marcado la diferencia.","title":"About"},{"location":"about/#este-blog-va-dirigido-a","text":"Este blog va dirigido a aquellas personas que disfrutan m\u00e1s monitorizando el entreno de una red neuronal que viendo un partido de su deporte favorito. Este blog va dirigido a aquellas personas que acompa\u00f1an su desayuno dominical con la lectura de un nuevo paper en lugar de con la serie que est\u00e9n echando en ese momento. Va dirigido a aquellas personas que no se conforman con usar programas o librer\u00edas como si de cajas negras se trataran, va dirigido a quienes quieren saber qu\u00e9 es lo que realmente pasa dentro de esa caja. Va dirigido a aquellas personas que aman los algoritmos y las matem\u00e1ticas. En definitiva, este blog va dirigido a gente como yo.","title":"Este blog va dirigido a..."},{"location":"about/#quien-soy-yo","text":"Aunque creo que con la secci\u00f3n superior ya te puedes hacer una buena idea de c\u00f3mo soy, es comprensible que quieras una descripci\u00f3n algo m\u00e1s formal de este blog y de su autor. Me llamo Guillermo y estudi\u00e9 el grado de Ingenier\u00eda Inform\u00e1tica en la Universidad de Alicante (Espa\u00f1a). Lo finaliz\u00e9 en 2016 y desde entonces mi vida profesional se resume en 3 a\u00f1os de trabajo en SolidQ , una consultora partners de Microsoft especializada en el tratamiento de los datos en todas sus variantes. Fue all\u00ed donde puse en pr\u00e1ctica mis conocimiento te\u00f3ricos de Machine Learning (ML) y donde aprend\u00ed a tratar con clientes. Despu\u00e9s de mis 3 a\u00f1os en SolidQ, a finales del verano del 2019, decid\u00ed tomarme un descanso para ver mundo y disfrutar del humilde placer del estudio de la inform\u00e1tica (ML y t\u00e9cnicas algor\u00edtmicas). Actualmente a\u00fan me encuentro disfrutando de este break y viajando sin rumbo fijo, viviendo al d\u00eda e improvisando el futuro cercano. No soy muy amigo de las redes sociales (con las redes neuronales ya tengo bastantes redes \ud83d\ude1c), pero de vez en cuando me dejo caer por alguna de ellas y... \u00a1hasta respondo a algunos mensajes! Cotill\u00e9ame los perfiles o s\u00edgueme para saber algo m\u00e1s de mi y enterarte de las futuras novedades de este blog.","title":"\u00bfQui\u00e9n soy yo?"},{"location":"about/#por-que-este-blog","text":"La cantidad de experimentos y c\u00f3digo que he escrito en mi ordenador es muy grande, pero pocos de ellos han visto la luz. Es una pena que todo ese contenido y todos los conocimientos que he ido adquiriendo despu\u00e9s de a\u00f1os de estudio se queden solo a mi disposici\u00f3n. Este blog pretende recopilar muchos de esos contenidos para que cualquiera con una conexi\u00f3n a Internet pueda sacarles partido. Tambi\u00e9n, adem\u00e1s de ayudar a otra gente, mis art\u00edculos pretenden ayudar al Guillermo del futuro. No todo lo aprendido se retiene eternamente, as\u00ed que me vendr\u00e1 bien refrescar lo aprendido leyendo mis propios art\u00edculos. Creedme, no hay mejores explicaciones para uno mismo que las que uno mismo escribi\u00f3. La idea de crear un blog como \u00e9ste viene de muy atr\u00e1s, pero la falta de tiempo y mi perfeccionismo no me dej\u00f3 empezarlo... hasta hoy. Es aqu\u00ed donde me veo obligado a citar a Reid Hoffman. \"Si no te averg\u00fcenza la primera versi\u00f3n de tu producto, lo lanzaste muy tarde\" -- Reid Hoffman, cofundador de LinkedIn Prometi\u00e9ndome a m\u00ed mismo encontrar un punto de perfeccionismo que me permita empezar a publicar art\u00edculos sin perder demasiada calidad, doy a luz a este blog.","title":"\u00bfPor qu\u00e9 este blog?"},{"location":"about/#dedicatoria","text":"Me gustar\u00eda agradecer p\u00fablicamente a todos aquellos que han hecho posible que me haya iniciado en el mundo de la inform\u00e1tica. Son ya muchos a\u00f1os los que llevo estudiando de forma autodidacta a trav\u00e9s de Internet, as\u00ed que me gustar\u00eda aprovechar bien esta dedicatoria agradeciendo a cada una de las personas que han compartido sus conocimientos de forma desinteresada en la red. Les agradezco de todo coraz\u00f3n sus aportes, aportes que entre la gran cantidad de datos que hay en Internet son insignificantes, pero que para m\u00ed han marcado la diferencia.","title":"Dedicatoria"},{"location":"tags/","text":"Tags Following is a list of relevant tags: Algorithms \ud83c\uddea\ud83c\uddf8 Reservoir sampling Best practices Do not number steps When to stop using Python notebooks Codeforces \ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function Euler \ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function Math \ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function Notebooks When to stop using Python notebooks Python When to stop using Python notebooks Random \ud83c\uddea\ud83c\uddf8 Reservoir sampling Statistics \ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 1 \ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 2","title":"Tags"},{"location":"tags/#tags","text":"Following is a list of relevant tags:","title":"Tags"},{"location":"tags/#algorithms","text":"\ud83c\uddea\ud83c\uddf8 Reservoir sampling","title":"Algorithms"},{"location":"tags/#best-practices","text":"Do not number steps When to stop using Python notebooks","title":"Best practices"},{"location":"tags/#codeforces","text":"\ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function","title":"Codeforces"},{"location":"tags/#euler","text":"\ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function","title":"Euler"},{"location":"tags/#math","text":"\ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function","title":"Math"},{"location":"tags/#notebooks","text":"When to stop using Python notebooks","title":"Notebooks"},{"location":"tags/#python","text":"When to stop using Python notebooks","title":"Python"},{"location":"tags/#random","text":"\ud83c\uddea\ud83c\uddf8 Reservoir sampling","title":"Random"},{"location":"tags/#statistics","text":"\ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 1 \ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 2","title":"Statistics"},{"location":"assets/notebooks/2020_01_27_reservoir_sampling/","text":"% matplotlib inline import matplotlib.pyplot as plt import numpy as np N_ELEMENTS = 10 SEED = 124 def get_random_list ( n_elements ): np . random . seed ( SEED ) random_list = np . arange ( 0 , n_elements ) - n_elements random_list = np . random . permutation ( random_list ) return random_list random_list = get_random_list ( N_ELEMENTS ) random_list array([ -4, -2, -7, -5, -6, -10, -1, -8, -3, -9]) #len(iter(random_list)) def sample_list ( random_iter ): random_list = [ i for i in random_iter ] length = len ( random_list ) idx = np . random . randint ( 0 , length - 1 ) return random_list [ idx ] sample_list ( iter ( random_list )) -10 def test_sample_method ( method , random_list , n_times ): samples = [] for i in range ( n_times ): samples . append ( method ( iter ( random_list ))) plt . hist ( samples ) test_sample_method ( sample_list , random_list , 40 ) test_sample_method ( sample_list , random_list , 10000 ) def sample_list ( random_iter ): random_list = [ i for i in random_iter ] length = len ( random_list ) idx = np . random . randint ( 0 , length ) return random_list [ idx ] test_sample_method ( sample_list , random_list , 10000 ) def sample_reservoir ( random_iter ): sample = next ( random_iter ) for i , n in enumerate ( random_iter ): if np . random . randint ( 0 , i + 1 ) == 0 : sample = n return sample sample_reservoir ( iter ( random_list )) -8 test_sample_method ( sample_list , random_list , 10000 )","title":"2020 01 27 reservoir sampling"},{"location":"best_practices/","text":"Best Practices In this section I will go through what I consider to be bad data engineering practices and how I think they should be better addressed. Although focused on data engineering, which is what pays my bills, many of the recipes presented here can also be useful in multiple disciplines. Danger All the posts in this section are highly opinionated . Feel free to reach out to me and start a discussion if you do not agree with some of them.","title":"Best Practices"},{"location":"best_practices/#best-practices","text":"In this section I will go through what I consider to be bad data engineering practices and how I think they should be better addressed. Although focused on data engineering, which is what pays my bills, many of the recipes presented here can also be useful in multiple disciplines. Danger All the posts in this section are highly opinionated . Feel free to reach out to me and start a discussion if you do not agree with some of them.","title":"Best Practices"},{"location":"best_practices/do_not_number_steps/","tags":["Best practices"],"text":"Do not number steps TLDR Do not use numbers to set an order in your modules/functions/files/notebooks. They just increase the cognitive load and leads to errors. If you want to know the order of execution go to your orchestrator or main function that calls them. In data engineering projects I have very often come across projects with a folder structure similar to the following one: my_project/ \u251c\u2500 src/ \u2502 \u251c\u2500 01_base_extract.py \u2502 \u251c\u2500 02_custom_extract.py \u2502 \u251c\u2500 03_base_transformations.py \u2502 \u251c\u2500 04_join_sources.py \u2502 \u251c\u2500 ... more files here ... Sometimes it is even more bizarre: my_project/ \u251c\u2500 src/ \u2502 \u251c\u2500 01_extract/ \u2502 \u2502 \u251c\u2500 01_01_base_extract.py \u2502 \u2502 \u251c\u2500 01_02_custom_extract.py \u2502 \u251c\u2500 02_transform/ \u2502 \u2502 \u251c\u2500 02_01_base_transformations.py \u2502 \u2502 \u251c\u2500 02_02_join_sources.py \u2502 \u251c\u2500 ... more folders and files here ... When I see something like this my first reaction is to cry . Please, do NOT number the steps of your process in you code . Note Numbering here means provide explicit order in the name. Using letters like a, b, c... is also equivalent to numbering. What will happen if you use numbers In these two previous examples the situation does not seem that bad, but let me explain what is going to happen when those greenfield projects have been active developed for a few more months. Let's use the second list of files as an example. It is quite likely that the directory structure will end up looking like this: my_project/ \u251c\u2500 src/ \u2502 \u251c\u2500 01_extract/ \u2502 \u2502 \u251c\u2500 01_00_setup_extractions.py \u2502 \u2502 \u251c\u2500 01_00b_setup_custom_extract.py \u2502 \u2502 \u251c\u2500 01_02_custom_extract.py \u2502 \u2502 \u251c\u2500 01_02b_custom_extract.py \u2502 \u2502 \u251c\u2500 01_02b_custom_extract_v2.py \u2502 \u2502 \u251c\u2500 01_03_new_base_extract_v2.py \u2502 \u2502 \u251c\u2500 01_05_extract_other_source.py \u2502 \u251c\u2500 02_transform/ \u2502 \u2502 \u251c\u2500 02_01_base_transformations.py \u2502 \u2502 \u251c\u2500 02_02_join_sources.py \u2502 \u2502 \u251c\u2500 01_03_new_base_transformations.py \u2502 \u251c\u2500 ... more folders and files here ... Some horrible things have happened: A new file called 01_00_setup_extractions.py has been added, and with it a new minimum step number. The lower step is now 0, not 1 as before. I wonder what will happen if any step before zero is necessary... Step -1? A new letter suffix has appeared. What does a \"b\" means after the number in 01_02b_custom_extract.py ? Is it a new step between step 02 and 03 or is this new file replacing the previous 01_02_custom_extract.py ? Some human with a VCS complex started adding versions to the filenames, like in 01_02b_custom_extract_v2.py . GIT does this for you! Where is version 1? Where is version \"a\"? Where is extract step 04? Is 01_03_new_base_transformations.py in the correct folder? It starts by 01 , but it is inside 02_transform/ and it contains the word transformations in the file name. Some even more horrible things that could have happened: The orchestrator that defines the execution order of these files calls 01_03_new_base_extract_v2.py first rather than 01_02b_custom_extract_v2.py . The orchestrator calls neither 01_00_setup_extractions.py nor 01_02_custom_extract.py . So we are keeping older versions of our steps in our codebase. Some other outlandish stuff that I cannot even imagine now . Although this almost-real example may have dispelled many doubts as to why I think using numbers is not the best thing to do, let's look at it on more detail. Why not to number? Code is dynamic , we are continuously adding/removing features. If we only added new files at the end there would not be much of a problem, but sometimes we modify, delete or add new files at intermediate positions. What we consider step 2 at the beginning of the project could be step 10 at the end. If we need to add a new step between the step 1 and 2 we usually have two options: We rename all the steps from 2 onwards. We make up a new naming strategy: 1a , 1b , 1_1 , 1.1 ... Renaming takes time, introduces a lot of noise on PRs, it is risky if we do not update the code that call/uses those files (specially if we do not have proper tests, really common on data projects)... Creating intermediate steps is confusing, specially if the new step is not related at all with the previous step. If we have a file numbered with a 1 and another one with 1.1 , we expect 1.1 to be a sub-step of step 1 . A similar situation takes place if we remove one step. Our two options are: Rename all the following steps. Leave a hole in the step list. First option has the same downsides as before, the second one can also lead to confusions: Are we missing a file? Was it deleted for some reason? Did someone number the files wrong by mistake? But there is something else... Some main process needs to call those files. The runner/orchestrator does not know about numbers, numbers are just characters in the filename. We are the ones in charge of defining the order of execution in the orchestrator and that leads to even more confusion. We are completely free to call step 4 first, then step 1 and later step 3 and do not even call step 2. This means that the filenames are not reflecting the real order, they are just there to increase the cognitive load of developers. Note In this post we are mainly talking about filenames, but the same applies to function names. If you have functions that need to be run in sequence you always have a main function that calls them. That would be the orchestrator of your process. Proposed solution The proposed solution is to clearly define a main/orchestrator file that sets the order. We can have a list of steps somewhere in the code, something like: orchestrator.py call ( \"extract/base_extract.py\" ) call ( \"extract/custom_extract.by\" ) call ( \"transform/base_transformations.by\" ) call ( \"transform/join_sources.by\" ) If we are not using numbers and we want to add a new step, we do not need to modify any existing code or filename. We just need to add a new line in the orchestrator. orchestrator.py with new step added call ( \"extract/base_extract.py\" ) call ( \"extract/extract_another_source.py\" ) # <-- New line call ( \"extract/custom_extract.py\" ) call ( \"transform/base_transformations.py\" ) call ( \"transform/join_sources.py\" ) If someone wants to know the exact order should go to that file. Conclusion Do not use numbers in function/module/file names, they lead to confusion. Define the order in code, you can always trust the order of a piece of code that orchestrate your process.","title":"Do not number steps"},{"location":"best_practices/do_not_number_steps/#do-not-number-steps","text":"TLDR Do not use numbers to set an order in your modules/functions/files/notebooks. They just increase the cognitive load and leads to errors. If you want to know the order of execution go to your orchestrator or main function that calls them. In data engineering projects I have very often come across projects with a folder structure similar to the following one: my_project/ \u251c\u2500 src/ \u2502 \u251c\u2500 01_base_extract.py \u2502 \u251c\u2500 02_custom_extract.py \u2502 \u251c\u2500 03_base_transformations.py \u2502 \u251c\u2500 04_join_sources.py \u2502 \u251c\u2500 ... more files here ... Sometimes it is even more bizarre: my_project/ \u251c\u2500 src/ \u2502 \u251c\u2500 01_extract/ \u2502 \u2502 \u251c\u2500 01_01_base_extract.py \u2502 \u2502 \u251c\u2500 01_02_custom_extract.py \u2502 \u251c\u2500 02_transform/ \u2502 \u2502 \u251c\u2500 02_01_base_transformations.py \u2502 \u2502 \u251c\u2500 02_02_join_sources.py \u2502 \u251c\u2500 ... more folders and files here ... When I see something like this my first reaction is to cry . Please, do NOT number the steps of your process in you code . Note Numbering here means provide explicit order in the name. Using letters like a, b, c... is also equivalent to numbering.","title":"Do not number steps"},{"location":"best_practices/do_not_number_steps/#what-will-happen-if-you-use-numbers","text":"In these two previous examples the situation does not seem that bad, but let me explain what is going to happen when those greenfield projects have been active developed for a few more months. Let's use the second list of files as an example. It is quite likely that the directory structure will end up looking like this: my_project/ \u251c\u2500 src/ \u2502 \u251c\u2500 01_extract/ \u2502 \u2502 \u251c\u2500 01_00_setup_extractions.py \u2502 \u2502 \u251c\u2500 01_00b_setup_custom_extract.py \u2502 \u2502 \u251c\u2500 01_02_custom_extract.py \u2502 \u2502 \u251c\u2500 01_02b_custom_extract.py \u2502 \u2502 \u251c\u2500 01_02b_custom_extract_v2.py \u2502 \u2502 \u251c\u2500 01_03_new_base_extract_v2.py \u2502 \u2502 \u251c\u2500 01_05_extract_other_source.py \u2502 \u251c\u2500 02_transform/ \u2502 \u2502 \u251c\u2500 02_01_base_transformations.py \u2502 \u2502 \u251c\u2500 02_02_join_sources.py \u2502 \u2502 \u251c\u2500 01_03_new_base_transformations.py \u2502 \u251c\u2500 ... more folders and files here ... Some horrible things have happened: A new file called 01_00_setup_extractions.py has been added, and with it a new minimum step number. The lower step is now 0, not 1 as before. I wonder what will happen if any step before zero is necessary... Step -1? A new letter suffix has appeared. What does a \"b\" means after the number in 01_02b_custom_extract.py ? Is it a new step between step 02 and 03 or is this new file replacing the previous 01_02_custom_extract.py ? Some human with a VCS complex started adding versions to the filenames, like in 01_02b_custom_extract_v2.py . GIT does this for you! Where is version 1? Where is version \"a\"? Where is extract step 04? Is 01_03_new_base_transformations.py in the correct folder? It starts by 01 , but it is inside 02_transform/ and it contains the word transformations in the file name. Some even more horrible things that could have happened: The orchestrator that defines the execution order of these files calls 01_03_new_base_extract_v2.py first rather than 01_02b_custom_extract_v2.py . The orchestrator calls neither 01_00_setup_extractions.py nor 01_02_custom_extract.py . So we are keeping older versions of our steps in our codebase. Some other outlandish stuff that I cannot even imagine now . Although this almost-real example may have dispelled many doubts as to why I think using numbers is not the best thing to do, let's look at it on more detail.","title":"What will happen if you use numbers"},{"location":"best_practices/do_not_number_steps/#why-not-to-number","text":"Code is dynamic , we are continuously adding/removing features. If we only added new files at the end there would not be much of a problem, but sometimes we modify, delete or add new files at intermediate positions. What we consider step 2 at the beginning of the project could be step 10 at the end. If we need to add a new step between the step 1 and 2 we usually have two options: We rename all the steps from 2 onwards. We make up a new naming strategy: 1a , 1b , 1_1 , 1.1 ... Renaming takes time, introduces a lot of noise on PRs, it is risky if we do not update the code that call/uses those files (specially if we do not have proper tests, really common on data projects)... Creating intermediate steps is confusing, specially if the new step is not related at all with the previous step. If we have a file numbered with a 1 and another one with 1.1 , we expect 1.1 to be a sub-step of step 1 . A similar situation takes place if we remove one step. Our two options are: Rename all the following steps. Leave a hole in the step list. First option has the same downsides as before, the second one can also lead to confusions: Are we missing a file? Was it deleted for some reason? Did someone number the files wrong by mistake? But there is something else... Some main process needs to call those files. The runner/orchestrator does not know about numbers, numbers are just characters in the filename. We are the ones in charge of defining the order of execution in the orchestrator and that leads to even more confusion. We are completely free to call step 4 first, then step 1 and later step 3 and do not even call step 2. This means that the filenames are not reflecting the real order, they are just there to increase the cognitive load of developers. Note In this post we are mainly talking about filenames, but the same applies to function names. If you have functions that need to be run in sequence you always have a main function that calls them. That would be the orchestrator of your process.","title":"Why not to number?"},{"location":"best_practices/do_not_number_steps/#proposed-solution","text":"The proposed solution is to clearly define a main/orchestrator file that sets the order. We can have a list of steps somewhere in the code, something like: orchestrator.py call ( \"extract/base_extract.py\" ) call ( \"extract/custom_extract.by\" ) call ( \"transform/base_transformations.by\" ) call ( \"transform/join_sources.by\" ) If we are not using numbers and we want to add a new step, we do not need to modify any existing code or filename. We just need to add a new line in the orchestrator. orchestrator.py with new step added call ( \"extract/base_extract.py\" ) call ( \"extract/extract_another_source.py\" ) # <-- New line call ( \"extract/custom_extract.py\" ) call ( \"transform/base_transformations.py\" ) call ( \"transform/join_sources.py\" ) If someone wants to know the exact order should go to that file.","title":"Proposed solution"},{"location":"best_practices/do_not_number_steps/#conclusion","text":"Do not use numbers in function/module/file names, they lead to confusion. Define the order in code, you can always trust the order of a piece of code that orchestrate your process.","title":"Conclusion"},{"location":"best_practices/when_to_stop_using_notebooks/","tags":["Best practices","Notebooks","Python"],"text":"When to stop using Python notebooks TLDR Use notebooks just for ad-hoc projects, PoCs, experiments or when you need visualizations. Use Python packages for any other use case. In both data engineering and data science , the use of notebooks is widespread . It is very easy and intuitive to open a Jupyter/Databricks notebook in your favourite browser and start executing commands. Pretty much anyone can train a machine learning model coping and pasting 4 lines of code. Writing code to migrate 100 tables from one storage account to another can be done in a matter of minutes. This ease of use is a positive aspect of notebooks, but they can also be a double-edged sword if you don't know when to stop using them . As a data engineer, I have come across many large projects that are purely developed with notebooks. Notebooks are a powerful tool, do not get me wrong, but they are not suitable for all use cases. In this document I will go through the main reasons why notebooks are not the best option when we want to create a serious product or a library/framework that can be used across multiple projects. This post is mainly focus on Python and Databricks and, of course, is very opinionated. I will be happy to discuss any of the points presented here with anyone who disagrees. What is a product/library/framework? I just said that using notebooks for products, libraries or frameworks is not the right thing to do. What do I mean by products, libraries or frameworks? What are the characteristics of such projects? We need quality code. This includes the usage of linters, type checkers and consistent formatting and import order. Tested code. The more projects are using the library/framework the more important it is to have them well tested and maintained. You want to have a better control of your requirements. Consistent versioning: do not overwrite old versions with new code. If a project is using an specific version of your library, the artifact stored under that version number should never change. Libraries/frameworks should be easy to use across different projects, more than one version should exists at the same time to support old projects that are not up to date. In general, products, libraries and frameworks should be reliable, well tested, and they need to follow the best software engineering practices. This post does not apply for ad-hoc analytics, PoCs or any quick and dirty projects. What is the alternative? OK, notebooks are not good enough for you, so what is the alternative? Very good question! The standard way to produce and distribute Python software is using packages. A package is nothing more than a series of files with code that is somehow related. In other words, a compressed file containing code created for a specific purpose. You have probably used packages before. For example, when you run: pip install pandas You are telling pip to look for the Pandas package in the public package index and install it in your environment. Instead of writing notebooks, the alternative proposed in this post is the creation of one or more Python packages and maintain that package as if it were a normal Python project. Software engineering has evolved a lot in the last 50 years and the development of a Python package is compatible with all these best practices. Notebooks, on the other hand, are a step backwards in many of these aspects. Keep reading to find out what I mean. Note Although this post is mainly about Python, all the information here applies to any other language. For example, Scala can be used in notebooks but you can also create Jar packages (the equivalent of Python's Wheel) using sbt . Boilerplate code VS Python package We do not usually start new projects from an empty directory. In the best case we have a template that we clone, other times we just copy and existing project and remove those parts that are not needed for our new project. If you are building some kind of internal framework for your company, you need to clarify the differences between your framework and the projects that are going to use it. Having a Python package does not mean that we no longer need a project template which we have to clone when we want to start new projects. It is still absolutely necessary. The main difference is that the boilerplate code you need should be as minimal as possible. Project templates should call functions defined in the library and there should be no business logic in them, just a skeleton ready to be completed by the developer. It is also possible to have a library with common code and import it from a notebook! The important thing is that the library with common code should be a Python package that follows good practices. Who, how and when we use the library is out of scope of this post. Tip CookieCutter is a nice tool for building templates :) Comparison Magic and DBUtils Python magic and Databricks DBUtils are cool, but they only work on Jupyter/Databricks. When we work on notebooks it is really easy to end up using this kind of tools. For example, if you avoid using %run because it cannot be done in a Python package, you will get much more portable code. DBUtils can be used from a Python package, but it is not as easy as writing dbutils . If you develop locally and you want your code to run locally you will prioritize different tools/options before using DBUtils, which gives you again more portable code. Run magic VS Python imports Databricks has a Python magic used to run other notebooks. In addition to making the code less portable, the use of %run can lead to other problems. The %run magic works as a C/C++ preprocessor, it copies all the code from a different notebook into the current notebook and runs it. Why is this bad? You overwrite existing functions, imported modules and local variables. Here you have a real example I have found some months ago: notebook1.py # Cell 1 from datetime import datetime datetime . now () notebook2.py # Cell 1 import datetime # Cell 2 % run ./ notebook1 # Cell 3 datetime . datetime . now () # BOOOOOOOOOOOOM!!! # AttributeError: type object 'datetime.datetime' has no attribute 'datetime' In notebook2.py we import datetime first and later we copy and paste the notebook1.py code in cell 2. This runs from datetime import datetime and overwrites the existing datetime module. Cell 3 fails for obvious reasons. Besides that, after running more than one notebook with %run it is not easy to know where a function has been defined. It is equivalent to Python's from x import * , something strongly discouraged because it makes the code very difficult to follow and can overwrite existing local variables. It is specially difficult in notebooks where we cannot use the Go to definition option that we usually have in powerful IDEs. Moreover, sometimes even the powerful IDEs and their linters cannot tell where functions come from if the fearsome import * is used. Finally, if we execute two %run ./notebook1 in a row on the same notebook it will run twice. This is a problem especially if there is any code other than function definitions. Python imports take this into account and do not re-run code that has already been imported. In Databricks we can also use dbutils.notebook.run to run notebooks, but they are executed in a different process, so we cannot compare that with Python imports. Share folders VS Python Package Index A common way to deploy projects made with notebooks is to copy the files to a shared directory such as /Share in Databricks. This brings two main problems. It complicates the deployment process if we want to maintain more than one version at the same time . Imagine that you are working on an internal framework for your company. This kind of framework is used in more than one project at the same time. Older and still active projects may require an older version of the utility library, if only the latest version is deployed, copies of the utility library will end up being made within each project's repository to ensure that a new version will not break the existing code. A folder structure like /Shared/my_package/v0.1 , /Shared/my_package/v0.2 ... can be created but you need to check that all your %runs in your project are pointing to the same required version. Normally, as the name suggests, the /Share directory is accessible by everyone , so we can make accidental modifications while reading those files in the Databricks Workspace or, even worse, hot fixes that are applied on the deployed files are never applied in the repository so they are lost after the next deployments. Once a version is deployed is should never be modified. Databricks has the option of using Git repositories. I honestly never explored in-depth that feature, but it looks to be impossible to maintain more than one version of your code published at the same time. Artifactory or any server that allow us to deploy Python packages can solve this problems. Every deployment should have a different version, you cannot replace existing deployed versions. In your cluster or in your job definition you can specify the version you want to use in your project and you can upgrade it when you decide. No more errors due to breaking changes in your dependencies. Besides that, if the update does not contains breaking changes, you do not need to modify the source files at all. We do not need to go through all the import statements and update the path, imports do not use paths like %run does. And we do not need to modify the PYTHONPATH environment variable at all, just write a normal Python import. Tip Semantic versioning can be easily applied to Python packages. It can even be automated using tools like semantic-release . Dependency management In Python packages you can include dependencies and specify the minimum and maximum compatible versions. You can also use tools like Poetry or pip-compile to lock the versions of the dependencies. This is difficult to achieve in notebooks. Locking your dependencies is specially useful when creating Docker images for our products . We must be able to exactly reproduce the build of our images. If instead of creating our images with the already tested dependencies (the ones in our lock file) we rely on the latest versions installed by pip , there is no guarantee that the code will work. For libraries/frameworks we should include the information about our dependencies within the package. I do not mean to include all the related wheels inside our wheel, no, just the metadata of what packages and versions need to be installed with our package. I have seen libraries that contain a requirements.txt file with pinned versions of its dependencies, but the package is build without any information about those dependencies. Tip You know that your package does not have metadata about your requirements when you run a pip install <your-package> and just your package is installed. When using Poetry always use poetry add <your-dependency> instead of pip install <your-dependency> . The latter just installs the dependency in your local environment and does not add it to the package. Warning Remember to add your dependencies with lower and upper bounds on the versions to avoid surprises. Local development Using Python libraries you can build, run and test your code locally, saving costs in cloud computing. Most of the time we do not need to work on big clusters or even on small clusters. Why to pay for a head node + 1 worker node while we are just writing a complex query for 30 min? Write the code locally, test the code with some sample data, deploy your code once you are sure it is working and run it on production data. No more excuses like I couldn't develop because my internet was down ! With local development comes the use of well-known Python tools like: Linters: pylint , flake8 ... Type checkers: pyright , mypy ... Testing frameworks: pytest ... Style checkers/formatters: Black ... Your favourite IDE: VIM , PyCharm , VSCode ... Python packages downsides Nothing is perfect. With the use of Python packages come several problems: The learning curve is steeper . Especially in the world of data, many people have only worked with notebooks and understanding how Python packages work can take some extra time for them. I am not saying it is difficult, but it does require some time which may delay the project. Libraries induce to abstract concepts using classes. Like notebooks, object-oriented programming (OOP) is very powerful, but needs to be used well. Unnecessarily complex design can lead to unmaintainable projects. The right balance between abstraction and complexity must be found. I know it is possible to use classes on notebooks but, in my experience, people get crazier with classes when they work in libraries. Especially if their goal is to create a super flexible framework. Performance tuning is a bit more difficult. A performance issue is usually detected in the performance environment at best, or in the production environment at worst. To work in such cases we need to test different queries on a large collection of data that we cannot have locally. Copy and paste functions/queries from the package into a notebook in an environment with a lot of data may be needed. Another option is to build and deploy the package each time a new change is made, which can be awkward. Most companies work with private code, so publishing to the public package index is not an option. We need a private package index or just deploy wheel files to a storage location. The recommended option is to have our own private repository, otherwise deploying wheels in a storage folder becomes very similar (and risky) as deploying notebooks in a directory. Setting up a package index server is not difficult but, again, it needs to be done by someone. Conclusions When are notebooks useful? When we want to run ad-hoc queries/visualizations. When prototyping or running PoCs. When we want to experiment with data that takes some time to load in memory. When notebooks should be avoided? When we want to deliver or reuse the solution as a whole (wheel package). When we want to have a better control on the versions (including parallel versions). When proper testing is needed, including coverage and test reports. When we want to develop locally. When we want to write cloud-agnostic code ( dbutils and some of the magic work only on Databricks). When you want to use linters like pylint or flake8 , type checkers like pyright , your favourite IDE (VIM ), auto formatting tools like Black ... In general, any tool that works with normal Python projects but do not integrate well with notebooks. As can be seen, there are many more reasons for not using them. Experiment as much as you want with notebooks, but please do not try to build a reliable and quality product around them. And if you do, please don't call me to maintain it.","title":"When to stop using Python notebooks"},{"location":"best_practices/when_to_stop_using_notebooks/#when-to-stop-using-python-notebooks","text":"TLDR Use notebooks just for ad-hoc projects, PoCs, experiments or when you need visualizations. Use Python packages for any other use case. In both data engineering and data science , the use of notebooks is widespread . It is very easy and intuitive to open a Jupyter/Databricks notebook in your favourite browser and start executing commands. Pretty much anyone can train a machine learning model coping and pasting 4 lines of code. Writing code to migrate 100 tables from one storage account to another can be done in a matter of minutes. This ease of use is a positive aspect of notebooks, but they can also be a double-edged sword if you don't know when to stop using them . As a data engineer, I have come across many large projects that are purely developed with notebooks. Notebooks are a powerful tool, do not get me wrong, but they are not suitable for all use cases. In this document I will go through the main reasons why notebooks are not the best option when we want to create a serious product or a library/framework that can be used across multiple projects. This post is mainly focus on Python and Databricks and, of course, is very opinionated. I will be happy to discuss any of the points presented here with anyone who disagrees.","title":"When to stop using Python notebooks"},{"location":"best_practices/when_to_stop_using_notebooks/#what-is-a-productlibraryframework","text":"I just said that using notebooks for products, libraries or frameworks is not the right thing to do. What do I mean by products, libraries or frameworks? What are the characteristics of such projects? We need quality code. This includes the usage of linters, type checkers and consistent formatting and import order. Tested code. The more projects are using the library/framework the more important it is to have them well tested and maintained. You want to have a better control of your requirements. Consistent versioning: do not overwrite old versions with new code. If a project is using an specific version of your library, the artifact stored under that version number should never change. Libraries/frameworks should be easy to use across different projects, more than one version should exists at the same time to support old projects that are not up to date. In general, products, libraries and frameworks should be reliable, well tested, and they need to follow the best software engineering practices. This post does not apply for ad-hoc analytics, PoCs or any quick and dirty projects.","title":"What is a product/library/framework?"},{"location":"best_practices/when_to_stop_using_notebooks/#what-is-the-alternative","text":"OK, notebooks are not good enough for you, so what is the alternative? Very good question! The standard way to produce and distribute Python software is using packages. A package is nothing more than a series of files with code that is somehow related. In other words, a compressed file containing code created for a specific purpose. You have probably used packages before. For example, when you run: pip install pandas You are telling pip to look for the Pandas package in the public package index and install it in your environment. Instead of writing notebooks, the alternative proposed in this post is the creation of one or more Python packages and maintain that package as if it were a normal Python project. Software engineering has evolved a lot in the last 50 years and the development of a Python package is compatible with all these best practices. Notebooks, on the other hand, are a step backwards in many of these aspects. Keep reading to find out what I mean. Note Although this post is mainly about Python, all the information here applies to any other language. For example, Scala can be used in notebooks but you can also create Jar packages (the equivalent of Python's Wheel) using sbt .","title":"What is the alternative?"},{"location":"best_practices/when_to_stop_using_notebooks/#boilerplate-code-vs-python-package","text":"We do not usually start new projects from an empty directory. In the best case we have a template that we clone, other times we just copy and existing project and remove those parts that are not needed for our new project. If you are building some kind of internal framework for your company, you need to clarify the differences between your framework and the projects that are going to use it. Having a Python package does not mean that we no longer need a project template which we have to clone when we want to start new projects. It is still absolutely necessary. The main difference is that the boilerplate code you need should be as minimal as possible. Project templates should call functions defined in the library and there should be no business logic in them, just a skeleton ready to be completed by the developer. It is also possible to have a library with common code and import it from a notebook! The important thing is that the library with common code should be a Python package that follows good practices. Who, how and when we use the library is out of scope of this post. Tip CookieCutter is a nice tool for building templates :)","title":"Boilerplate code VS Python package"},{"location":"best_practices/when_to_stop_using_notebooks/#comparison","text":"","title":"Comparison"},{"location":"best_practices/when_to_stop_using_notebooks/#magic-and-dbutils","text":"Python magic and Databricks DBUtils are cool, but they only work on Jupyter/Databricks. When we work on notebooks it is really easy to end up using this kind of tools. For example, if you avoid using %run because it cannot be done in a Python package, you will get much more portable code. DBUtils can be used from a Python package, but it is not as easy as writing dbutils . If you develop locally and you want your code to run locally you will prioritize different tools/options before using DBUtils, which gives you again more portable code.","title":"Magic and DBUtils"},{"location":"best_practices/when_to_stop_using_notebooks/#run-magic-vs-python-imports","text":"Databricks has a Python magic used to run other notebooks. In addition to making the code less portable, the use of %run can lead to other problems. The %run magic works as a C/C++ preprocessor, it copies all the code from a different notebook into the current notebook and runs it. Why is this bad? You overwrite existing functions, imported modules and local variables. Here you have a real example I have found some months ago: notebook1.py # Cell 1 from datetime import datetime datetime . now () notebook2.py # Cell 1 import datetime # Cell 2 % run ./ notebook1 # Cell 3 datetime . datetime . now () # BOOOOOOOOOOOOM!!! # AttributeError: type object 'datetime.datetime' has no attribute 'datetime' In notebook2.py we import datetime first and later we copy and paste the notebook1.py code in cell 2. This runs from datetime import datetime and overwrites the existing datetime module. Cell 3 fails for obvious reasons. Besides that, after running more than one notebook with %run it is not easy to know where a function has been defined. It is equivalent to Python's from x import * , something strongly discouraged because it makes the code very difficult to follow and can overwrite existing local variables. It is specially difficult in notebooks where we cannot use the Go to definition option that we usually have in powerful IDEs. Moreover, sometimes even the powerful IDEs and their linters cannot tell where functions come from if the fearsome import * is used. Finally, if we execute two %run ./notebook1 in a row on the same notebook it will run twice. This is a problem especially if there is any code other than function definitions. Python imports take this into account and do not re-run code that has already been imported. In Databricks we can also use dbutils.notebook.run to run notebooks, but they are executed in a different process, so we cannot compare that with Python imports.","title":"Run magic VS Python imports"},{"location":"best_practices/when_to_stop_using_notebooks/#share-folders-vs-python-package-index","text":"A common way to deploy projects made with notebooks is to copy the files to a shared directory such as /Share in Databricks. This brings two main problems. It complicates the deployment process if we want to maintain more than one version at the same time . Imagine that you are working on an internal framework for your company. This kind of framework is used in more than one project at the same time. Older and still active projects may require an older version of the utility library, if only the latest version is deployed, copies of the utility library will end up being made within each project's repository to ensure that a new version will not break the existing code. A folder structure like /Shared/my_package/v0.1 , /Shared/my_package/v0.2 ... can be created but you need to check that all your %runs in your project are pointing to the same required version. Normally, as the name suggests, the /Share directory is accessible by everyone , so we can make accidental modifications while reading those files in the Databricks Workspace or, even worse, hot fixes that are applied on the deployed files are never applied in the repository so they are lost after the next deployments. Once a version is deployed is should never be modified. Databricks has the option of using Git repositories. I honestly never explored in-depth that feature, but it looks to be impossible to maintain more than one version of your code published at the same time. Artifactory or any server that allow us to deploy Python packages can solve this problems. Every deployment should have a different version, you cannot replace existing deployed versions. In your cluster or in your job definition you can specify the version you want to use in your project and you can upgrade it when you decide. No more errors due to breaking changes in your dependencies. Besides that, if the update does not contains breaking changes, you do not need to modify the source files at all. We do not need to go through all the import statements and update the path, imports do not use paths like %run does. And we do not need to modify the PYTHONPATH environment variable at all, just write a normal Python import. Tip Semantic versioning can be easily applied to Python packages. It can even be automated using tools like semantic-release .","title":"Share folders VS Python Package Index"},{"location":"best_practices/when_to_stop_using_notebooks/#dependency-management","text":"In Python packages you can include dependencies and specify the minimum and maximum compatible versions. You can also use tools like Poetry or pip-compile to lock the versions of the dependencies. This is difficult to achieve in notebooks. Locking your dependencies is specially useful when creating Docker images for our products . We must be able to exactly reproduce the build of our images. If instead of creating our images with the already tested dependencies (the ones in our lock file) we rely on the latest versions installed by pip , there is no guarantee that the code will work. For libraries/frameworks we should include the information about our dependencies within the package. I do not mean to include all the related wheels inside our wheel, no, just the metadata of what packages and versions need to be installed with our package. I have seen libraries that contain a requirements.txt file with pinned versions of its dependencies, but the package is build without any information about those dependencies. Tip You know that your package does not have metadata about your requirements when you run a pip install <your-package> and just your package is installed. When using Poetry always use poetry add <your-dependency> instead of pip install <your-dependency> . The latter just installs the dependency in your local environment and does not add it to the package. Warning Remember to add your dependencies with lower and upper bounds on the versions to avoid surprises.","title":"Dependency management"},{"location":"best_practices/when_to_stop_using_notebooks/#local-development","text":"Using Python libraries you can build, run and test your code locally, saving costs in cloud computing. Most of the time we do not need to work on big clusters or even on small clusters. Why to pay for a head node + 1 worker node while we are just writing a complex query for 30 min? Write the code locally, test the code with some sample data, deploy your code once you are sure it is working and run it on production data. No more excuses like I couldn't develop because my internet was down ! With local development comes the use of well-known Python tools like: Linters: pylint , flake8 ... Type checkers: pyright , mypy ... Testing frameworks: pytest ... Style checkers/formatters: Black ... Your favourite IDE: VIM , PyCharm , VSCode ...","title":"Local development"},{"location":"best_practices/when_to_stop_using_notebooks/#python-packages-downsides","text":"Nothing is perfect. With the use of Python packages come several problems: The learning curve is steeper . Especially in the world of data, many people have only worked with notebooks and understanding how Python packages work can take some extra time for them. I am not saying it is difficult, but it does require some time which may delay the project. Libraries induce to abstract concepts using classes. Like notebooks, object-oriented programming (OOP) is very powerful, but needs to be used well. Unnecessarily complex design can lead to unmaintainable projects. The right balance between abstraction and complexity must be found. I know it is possible to use classes on notebooks but, in my experience, people get crazier with classes when they work in libraries. Especially if their goal is to create a super flexible framework. Performance tuning is a bit more difficult. A performance issue is usually detected in the performance environment at best, or in the production environment at worst. To work in such cases we need to test different queries on a large collection of data that we cannot have locally. Copy and paste functions/queries from the package into a notebook in an environment with a lot of data may be needed. Another option is to build and deploy the package each time a new change is made, which can be awkward. Most companies work with private code, so publishing to the public package index is not an option. We need a private package index or just deploy wheel files to a storage location. The recommended option is to have our own private repository, otherwise deploying wheels in a storage folder becomes very similar (and risky) as deploying notebooks in a directory. Setting up a package index server is not difficult but, again, it needs to be done by someone.","title":"Python packages downsides"},{"location":"best_practices/when_to_stop_using_notebooks/#conclusions","text":"When are notebooks useful? When we want to run ad-hoc queries/visualizations. When prototyping or running PoCs. When we want to experiment with data that takes some time to load in memory. When notebooks should be avoided? When we want to deliver or reuse the solution as a whole (wheel package). When we want to have a better control on the versions (including parallel versions). When proper testing is needed, including coverage and test reports. When we want to develop locally. When we want to write cloud-agnostic code ( dbutils and some of the magic work only on Databricks). When you want to use linters like pylint or flake8 , type checkers like pyright , your favourite IDE (VIM ), auto formatting tools like Black ... In general, any tool that works with normal Python projects but do not integrate well with notebooks. As can be seen, there are many more reasons for not using them. Experiment as much as you want with notebooks, but please do not try to build a reliable and quality product around them. And if you do, please don't call me to maintain it.","title":"Conclusions"},{"location":"math/maximum-likelihood-estimation-1/","tags":["Statistics"],"text":"\ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 1 Si hab\u00e9is llegado a este art\u00edculo de forma intencionada es muy posible que las palabras Maximum Likelihood Estimation os digan algo. Este art\u00edculo va dedicado a aquellas personas a las que esas palabras les dicen algo, pero algo que no entienden. En esta primera parte voy a explicar de forma sencilla y visual el conocido concepto de Maximum Likelihood Estimation , a menudo abreviado con las siglas MLE . En espa\u00f1ol el t\u00e9rmino es traducido como Estimaci\u00f3n por M\u00e1xima Verosimilitud (EMV), pero prefiero referirme a \u00e9l con el t\u00e9rmino ingl\u00e9s debido a que es como se puede encontrar en la gran mayor\u00eda de las publicaciones cient\u00edficas. En la segunda parte veremos un ejemplo de aplicaci\u00f3n del MLE. Monedas Cuando uno empieza a estudiar estad\u00edstica, en lo primero que repara es en lo importante que son las monedas. No creo que haya nadie que haya estudiado estad\u00edstica sin encontrarse con alg\u00fan ejemplo o ejercicio en el que se lancen monedas. En esta explicaci\u00f3n nos apoyaremos nuevamente en ellas. Cara y cruz Una moneda normal y corriente (que no est\u00e1 trucada), al ser lanzada existe la misma probabilidad de que caiga cara o de que caiga cruz. Eso lo expresaremos matem\u00e1ticamente como: \\(P(\\) \\() = P(\\) \\() = 0.5\\) Sin embargo, existen otras monedas en las que la probabilidad de que caiga cara es diferente a la probabilidad de que caiga cruz. Hablamos entonces de monedas trucadas . En estos casos vamos a designar a la probabilidad de que la moneda caiga cara con la letra \\(p\\) . Por lo tanto, la probabilidad de que salga cruz es \\(1 - p\\) (si no es cara, entonces es cruz). \\(P(\\) \\() = p\\) \\(P(\\) \\() = 1 - p\\) La expresi\u00f3n de encima de estas l\u00edneas funciona para cualquiera que sea el valor de \\(p \\in [0, 1]\\) . Como seguro os habr\u00e9is dado cuenta, cuando \\(p = 0.5\\) nos encontramos ante una moneda normal o no trucada. Este hecho hace de esta expresi\u00f3n una expresi\u00f3n mucho m\u00e1s general, es decir, sirve para cualquier tipo de moneda. Independencia de sucesos Es imprescindible darse cuenta de que si hacemos varios lanzamientos de monedas, son todos sucesos independientes entre s\u00ed. Si lanzas una moneda y cae cara \u00bfcondiciona ese hecho a que en el siguiente lanzamiento vuelva a salir cara? La respuesta es no. Veamos ahora unos ejemplos de c\u00f3mo se calcula la probabilidad de varios lanzamientos. \u00bfCu\u00e1l es la probabilidad de obtener , tras 2 lanzamientos con una moneda normal? Al tratarse de sucesos independientes entre s\u00ed, tenemos que \\(P(\\) , \\() = P(\\) \\() \\cdot P(\\) \\() = 0.5 \\cdot 0.5 = 0.25\\) . Es interesante darse cuenta que en este tipo de ejercicios no nos importa el orden de las monedas, puesto que: \\(P(\\) , \\() = P(\\) \\() \\cdot P(\\) \\() = P(\\) \\() \\cdot P(\\) \\() = P(\\) , \\()\\) . \u00bfCu\u00e1l es la probabilidad de obtener esa misma secuencia sea cual sea la moneda utilizada? Tanto si consideramos que la moneda est\u00e1 trucada como que no, obtenemos que \\(P(\\) , \\() = P(\\) \\() \\cdot P(\\) \\() = (1 - p) \\cdot p.\\) Si sustituimos \\(p\\) por \\(0.5\\) obtenemos ex\u00e1ctamente el mismo valor de antes, el valor para una moneda normal: \\((1 - 0.5) \\cdot 0.5 = 0.5 \\cdot 0.5 = 0.25\\) . \u00bfCu\u00e1l es la probabilidad de obtener , , si \\(p = 0.1\\) ? \\(P(\\) , , \\() = P(\\) \\() \\cdot P(\\) \\() \\cdot P(\\) \\() = P(\\) \\()^3 = 0.1^3 = 0.001\\) \u00bfCu\u00e1l es la probabilidad de obtener , , si \\(p = 0.9\\) ? \\(P(\\) , , \\() = P(\\) \\()^3 = 0.9^3 = 0.729\\) S\u00e9 lo que est\u00e1is pensando, \"\u00a1qu\u00e9 preguntas m\u00e1s tontas me est\u00e1 haciendo!\". Pues s\u00ed, son ejercicios muy f\u00e1ciles, pero quiero que os fij\u00e9is bien en las dos \u00faltimas preguntas y me dig\u00e1is qu\u00e9 valor de \\(p\\) consigue una probabilidad m\u00e1s alta. Con \\(p = 0.1\\) se consigue \\(0.001\\) y con \\(p = 0.9\\) se consigue \\(0.729\\) . \u00bfHay alg\u00fan otro valor de \\(p\\) que consiga un valor m\u00e1s alto de probabilidad para obtener 3 caras? La respuesta es s\u00ed, con \\(p = 1\\) se consigue una probabilidad de \\(1\\) . Si calculamos la probabilidad de obtener 3 caras en funci\u00f3n del par\u00e1metro \\(p\\) obtenemos \\(P(\\) , , \\() = P(\\) \\()^3 = p^3\\) . Ahora que tenemos esa expresi\u00f3n, vamos a representarla en una gr\u00e1fica. Puesto que \\(p\\) es una probabilidad, el valor de ese par\u00e1metro se encuentra dentro del intervalo \\(p \\in [0, 1]\\) . Sobre la l\u00ednea he marcado 3 puntos, los valores de \\(p\\) que ya hemos calculado. Comprobamos claramente que el valor de probabilidad m\u00e1s alto se obtiene cuando \\(p = 1\\) , lo que confirma nuestro anterior c\u00e1lculo. Por comentar algo m\u00e1s de la gr\u00e1fica, diremos que seg\u00fan ella no es posible obtener 3 caras cuando \\(p = 0\\) puesto que la funci\u00f3n vale 0 al inicio. Esto tiene mucho sentido puesto que no es posible obtener 3 caras al lanzar 3 veces una moneda en la que nunca sale cara. window.addEventListener('load', function(){ JXG.Options.text.useMathJax = true; var board = JXG.JSXGraph.initBoard('jxgbox1', { boundingbox: [-0.1, 1.1, 1.1, -0.1], showNavigation: false, axis: true }); var graph = board.create('functiongraph', [function(p){ var n_caras = 3; var n_cruces = 0; var max = n_caras / (n_caras + n_cruces); return Math.pow(p, n_caras) * Math.pow(1 - p, n_cruces); }, 0, 1]); var p1 = board.create('point', [0.1, 0.001], { label: true, fixed: true, name: \"\\\\[p = 0.1\\\\]\", label: { position: 'top', offset: [-10, 20] } }); var p2 = board.create('point', [0.9, 0.729], { label: false, fixed: true, name: \"\\\\[p = 0.9\\\\]\", label: { position: 'top', offset: [-10, 20] } }); var p3 = board.create('point', [1, 1], { label: false, fixed: true, name: \"\\\\[p = 1\\\\]\", label: { position: 'top', offset: [-10, 20] } }); board.create('text', [1.00, 0.06, function() { return '\\\\[p\\\\]'; }], {fixed: true}); board.fullUpdate(); }); Otro ejemplo Vamos a observar otro ejemplo distinto en el que tras tirar 10 veces una misma moneda obtenemos 8 caras y 2 cruces (recuerda que el orden no nos importa en absoluto, cualquier combinaci\u00f3n con 8 caras y 2 cruces tiene el mismo valor de probabilidad). A diferencia de antes, ahora en los resultados obtenidos encontramos tanto caras como cruces. \u00bfCu\u00e1l dir\u00edas que es el valor de \\(p\\) de dicha moneda? Posiblemente hayas realizado el c\u00e1lculo \\(p = \\frac{8 \\text{ caras}}{10 \\text{ lanzamientos}} = 0.8\\) . Pues lo cierto es que entre cualquier posible valor de \\(p\\) , el \\(0.8\\) es el valor m\u00e1s cre\u00edble, m\u00e1s veros\u00edmil, m\u00e1s plausible, m\u00e1s likelihood ... ll\u00e1malo como quieras. Si volvemos a representar la probabilidad en funci\u00f3n de \\(p\\) obtenemos la siguiente gr\u00e1fica: window.addEventListener('load', function(){ JXG.Options.text.useMathJax = true; var board = JXG.JSXGraph.initBoard('jxgbox2', { boundingbox: [-0.1, 1.1, 1.1, -0.1], showNavigation: false, axis: false, offsetX: 1 }); var yaxis = board.create('axis', [[0, 0], [0, 1]], { ticks: { insertTicks: true, drawLabels: false, minorTicks: 0 } }); var xaxis = board.create('axis', [[0, 0], [1, 0]], { ticks: { drawZero: true, minorTicks: 0, drawLabels: false } }); var xticks = board.create('ticks', [xaxis, [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]], { drawLabels: true, label : { offset: [-2.5, -17.4] } }); var n_caras = 8; var n_cruces = 2; var max = n_caras / (n_caras + n_cruces); var max_value = Math.pow(max, n_caras) * Math.pow(1 - max, n_cruces); var graph = board.create('functiongraph', [function (p) { return Math.pow(p, n_caras) * Math.pow(1 - p, n_cruces) / max_value; }, 0, 1]); var p3 = board.create('point', [max, 1], { showInfobox: false, label: false, fixed: true, name: \"(\" + max + \", \" + max_value.toExponential(2) + \")\" }); board.create('text',[0.1, 0.7, function() { return String.raw`\\[p ^ {n_{caras}} \\cdot (1 - p) ^ {n_{cruces}}\\]`; }], { fontSize: 24, highlightStrokeOpacity: 1, highlightFillOpacity: 1 }); board.create('text',[0.1, 0.5, function() { return String.raw`\\[n_{caras} = 8\\]`; }], { fontSize: 24, highlightStrokeOpacity: 1, highlightFillOpacity: 1 }); board.create('text',[0.1, 0.3, function() { return String.raw`\\[n_{cruces} = 2\\]`; }], { fontSize: 24, highlightStrokeOpacity: 1, highlightFillOpacity: 1 }); board.create('text',[1.06, -0.03, function() { return '\\\\[p\\\\]'; }], {fixed: true}); board.fullUpdate(); }); El valor \\(p = 0.8\\) es el m\u00e1s veros\u00edmil, pero al fin y al cabo, en 10 lanzamientos de una moneda normal ( \\(p = 0.5\\) ) puede pasar que nos salgan 8 caras. Es raro, pero puede pasar. Digamos que cambiamos el n\u00famero de lanzamientos por 100 y obtenemos 80 caras y 20 cruces, \u00bfcu\u00e1l dir\u00edas que es el valor de \\(p\\) ahora? Al igual que antes, \\(p = \\frac{80}{100} = 0.8\\) . Si representamos gr\u00e1ficamente la probabilidad en funci\u00f3n de \\(p\\) obtenemos algo muy similar a la \u00faltima gr\u00e1fica, solo que ahora el pico es mucho m\u00e1s estrecho, lo que podemos interpretar como que es menos probable que tirando una moneda normal se obtengan esos resultados. Antes dec\u00edamos que era raro obtener 8 caras de 10 lanzamientos con una moneda normal, ahora decimos que es muy muy muy muy raro, por no decir imposible, obtener 80 caras de 100 lanzamientos con una moneda normal (comprueba la altura de la curva de la siguiente gr\u00e1fica en \\(p = 0.5\\) con la de la gr\u00e1fica anterior). window.addEventListener('load', function(){ var board = JXG.JSXGraph.initBoard('jxgbox3', { boundingbox: [-0.1, 1.1, 1.1, -0.1], showNavigation: false, axis: false, offsetX: 1 }); var yaxis = board.create('axis', [[0, 0], [0, 1]], { ticks: { insertTicks: true, drawLabels: false, minorTicks: 0 } }); var xaxis = board.create('axis', [[0, 0], [1, 0]], { ticks: { drawZero: true, minorTicks: 0, drawLabels: false } }); var xticks = board.create('ticks', [xaxis, [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]], { drawLabels: true, label : { offset: [-2.5, -17.4] } }); var n_caras = 80; var n_cruces = 20; var max = n_caras / (n_caras + n_cruces); var max_value = Math.pow(max, n_caras) * Math.pow(1 - max, n_cruces); var graph = board.create('functiongraph', [function (p) { return Math.pow(p, n_caras) * Math.pow(1 - p, n_cruces) / max_value; }, 0, 1]); var p3 = board.create('point', [max, 1], { showInfobox: false, label: false, fixed: true, name: \"(\" + max + \", \" + max_value.toExponential(2) + \")\" }); board.create('text',[0.1, 0.7, function() { return String.raw`\\[p ^ {n_{caras}} \\cdot (1 - p) ^ {n_{cruces}}\\]`; }], { fontSize: 24, highlightStrokeOpacity: 1, highlightFillOpacity: 1 }); board.create('text',[0.1, 0.5, function() { return String.raw`\\[n_{caras} = 80\\]`; }], { fontSize: 24, highlightStrokeOpacity: 1, highlightFillOpacity: 1 }); board.create('text',[0.1, 0.3, function() { return String.raw`\\[n_{cruces} = 20\\]`; }], { fontSize: 24, highlightStrokeOpacity: 1, highlightFillOpacity: 1 }); board.create('text',[1.06, -0.03, function() { return '\\\\[p\\\\]'; }], {fixed: true}); board.fullUpdate(); }); Como hab\u00e9is podido observar, el valor de \\(p\\) que consigue la probabilidad m\u00e1s alta de una secuencia de lanzamientos se puede obtener con \\[\\dfrac{\\text{# caras}}{\\text{# lanzamientos}}\\] \u00bfDe d\u00f3nde sale esa f\u00f3rmula? Esa divisi\u00f3n que puede resultar muy natural y que usamos a menudo sin plantearnos de d\u00f3nde ha salido, se obtiene gracias al MLE (en la segunda parte de este art\u00edculo veremos c\u00f3mo se llega a ella). Por lo tanto, MLE nos permite obtener el valor de un par\u00e1metro (en nuestro caso \\(p\\) ) para que tengan lugar de forma m\u00e1s probable un conjunto de observaciones (resultados de los lanzamientos de una moneda). Muchos problemas de estad\u00edstica nos dicen: tenemos una moneda con \\(P(\\) \\() = p\\) , \u00bfcu\u00e1l es la probabilidad de obtener \\(X\\) secuencia de lanzamientos con ella?. MLE se utiliza para dar respuesta a otra pregunta ligeramente distinta: teniendo una secuencia de lanzamientos \\(X\\) , \u00bfcu\u00e1l es el valor de \\(p\\) que maximiza la probabilidad de obtener dicha secuencia? Pru\u00e9balo t\u00fa mismo Os he preparado un peque\u00f1o gr\u00e1fico interactivo que os ayudar\u00e1 a comprender las likelihood functions . En la parte superior del gr\u00e1fico hay un par de barras deslizantes que puedes cambiar a tu antojo. La primera de ellas corresponde al n\u00famero de veces que la moneda lanzada ha ca\u00eddo cara y la segunda de ellas al n\u00famero de veces que ha ca\u00eddo cruz. La funci\u00f3n representada no es m\u00e1s que la probabilidad en funci\u00f3n de \\(p\\) de obtener una serie de lanzamientos con ese n\u00famero de caras y cruces. Un punto rojo indica el m\u00e1ximo de la curva. window.addEventListener('load', function(){ var board = JXG.JSXGraph.initBoard('jxgbox4', { boundingbox: [-0.1, 1.3, 1.1, -0.1], showNavigation: false, axis: false }); var yaxis = board.create('axis', [[0, 0], [0, 1]], { ticks: { insertTicks: true, drawLabels: false, minorTicks: 0 } }); var xaxis = board.create('axis', [[0, 0], [1, 0]], { ticks: { drawZero: true, minorTicks: 0, drawLabels: false } }); var xticks = board.create('ticks', [xaxis, [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]], { fixed: true, drawLabels: true, label : { offset: [-2.5, -17.4] } }); var slider_caras = board.create('slider', [[0.1,1.2],[0.7,1.2],[0, 5, 10]], { //name: String.raw`\\[n_{caras}\\]`, name: 'n_{caras}', snapWidth: 1, precision: 0 }); var slider_cruces = board.create('slider', [[0.1,1.1],[0.7,1.1],[0, 5, 10]], { //name: String.raw`\\[n_{cruces}\\]`, name: 'n_{cruces}', snapWidth: 1, precision: 0 }); var p3 = board.create('point', [0.5, 1], { showInfobox: false, fixed: true, label: { position: 'top', offsets: [-50, 10] } }); var graph = board.create('functiongraph', [function(p){ var n_caras = slider_caras.Value(); var n_cruces = slider_cruces.Value(); var max = n_caras / (n_caras + n_cruces); var max_value = Math.pow(max, n_caras) * Math.pow(1 - max, n_cruces); if (p == 0) { // Importante para actualizar el punto m\u00e1ximo solo una vez y no cada punto de la curva. p3.setName(\"(\" + max.toFixed(2) + \", \" + max_value.toExponential(2) + \")\"); p3.setPosition(JXG.COORDS_BY_USER, [max, 1]); } return Math.pow(p, n_caras) * Math.pow(1 - p, n_cruces) / max_value; }, 0, 1]); board.fullUpdate(); }); Algunas observaciones Antes de terminar me gustar\u00eda aclarar algunas cosas que quiz\u00e1s respondan a dudas que te hayan surgido conforme le\u00edas el art\u00edculo. Puede que est\u00e9s pensando si el \u00e1rea que se encuentra bajo la curva (integral) de la funci\u00f3n likelihood debe de sumar 1. Eso no ocurre pr\u00e1cticamente nunca. En el ejemplo interactivo, parece que la funci\u00f3n siempre tenga su m\u00e1ximo a la misma altura, eso es debido a que se ha llevado a cabo un proceso de normalizaci\u00f3n con la idea de poder observar perfectamente la curva entera sin tener que hacer zoom en la figura. Cuanto mayor es el n\u00famero de lanzamientos, la altura m\u00e1xima de la curva disminuye a valores realmente bajos (con 10 caras y 10 cruces el m\u00e1ximo es del orden de \\(10^{-6}\\) ). En la pr\u00e1ctica, el valor de la funci\u00f3n no importa, s\u00f3lo nos importa d\u00f3nde se encuentra el m\u00e1ximo. Es por dicha raz\u00f3n por las que no se muestran las unidades del eje \\(y\\) . \u00bfHas jugado ya con el ejemplo interactivo? Si no lo has hecho te recomiendo por lo menos llevar a cabo alguna de estas pruebas. Pon a 0 las dos barras deslizantes. Despu\u00e9s selecciona una de ellas y ve aument\u00e1ndola poco a poco. \u00bfQu\u00e9 observas? Pon a 0 las dos barras deslizantes. Despu\u00e9s incrementa al mismo tiempo ambas barras. \u00bfQu\u00e9 observas? F\u00edjate tambi\u00e9n en el valor de probabilidad del punto m\u00e1ximo (la coordenada \\(y\\) del punto rojo) \u00bfQu\u00e9 le pasa conforme aumenta el n\u00famero total de lanzamientos? Para saber m\u00e1s Creo que con lo visto en este art\u00edculo ha quedado claro cu\u00e1l es el cometido del MLE. Para explicarlo no hemos hecho uso de expresiones matem\u00e1ticas complejas, solo estad\u00edstica b\u00e1sica. En la segunda parte de este art\u00edculo introduciremos notaci\u00f3n matem\u00e1tica y veremos en acci\u00f3n esta t\u00e9cnica de estimaci\u00f3n de par\u00e1metros. El ejemplo ser\u00e1 la derivaci\u00f3n matem\u00e1tica necesaria para llegar a obtener porqu\u00e9 el valor de \\(p\\) que m\u00e1s probabilidad consigue en cualquier secuencia de lanzamientos es \\(\\frac{\\text{# caras}}{\\text{# lanzamientos}}\\) . \u00a1Nos vemos en la segunda parte! Cr\u00e9ditos Las im\u00e1genes de las monedas son una modificaci\u00f3n propia de varios ficheros descargados desde Freepik . Las gr\u00e1ficas interactivas han sido hechas con la ayuda de la librer\u00eda JSXGraph . .coin, .head, .tail { background-size: cover; display: inline-block; height: 2em; width: 2em; vertical-align: middle; margin-top: 1px; } .head { background-image: url(\"/assets/images/2018_10_18_coin_head.png\"); } .tail { background-image: url(\"/assets/images/2018_10_18_coin_tail.png\"); }","title":"\ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 1"},{"location":"math/maximum-likelihood-estimation-1/#maximum-likelihood-estimation-parte-1","text":"Si hab\u00e9is llegado a este art\u00edculo de forma intencionada es muy posible que las palabras Maximum Likelihood Estimation os digan algo. Este art\u00edculo va dedicado a aquellas personas a las que esas palabras les dicen algo, pero algo que no entienden. En esta primera parte voy a explicar de forma sencilla y visual el conocido concepto de Maximum Likelihood Estimation , a menudo abreviado con las siglas MLE . En espa\u00f1ol el t\u00e9rmino es traducido como Estimaci\u00f3n por M\u00e1xima Verosimilitud (EMV), pero prefiero referirme a \u00e9l con el t\u00e9rmino ingl\u00e9s debido a que es como se puede encontrar en la gran mayor\u00eda de las publicaciones cient\u00edficas. En la segunda parte veremos un ejemplo de aplicaci\u00f3n del MLE.","title":"\ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 1"},{"location":"math/maximum-likelihood-estimation-1/#monedas","text":"Cuando uno empieza a estudiar estad\u00edstica, en lo primero que repara es en lo importante que son las monedas. No creo que haya nadie que haya estudiado estad\u00edstica sin encontrarse con alg\u00fan ejemplo o ejercicio en el que se lancen monedas. En esta explicaci\u00f3n nos apoyaremos nuevamente en ellas. Cara y cruz Una moneda normal y corriente (que no est\u00e1 trucada), al ser lanzada existe la misma probabilidad de que caiga cara o de que caiga cruz. Eso lo expresaremos matem\u00e1ticamente como: \\(P(\\) \\() = P(\\) \\() = 0.5\\) Sin embargo, existen otras monedas en las que la probabilidad de que caiga cara es diferente a la probabilidad de que caiga cruz. Hablamos entonces de monedas trucadas . En estos casos vamos a designar a la probabilidad de que la moneda caiga cara con la letra \\(p\\) . Por lo tanto, la probabilidad de que salga cruz es \\(1 - p\\) (si no es cara, entonces es cruz). \\(P(\\) \\() = p\\) \\(P(\\) \\() = 1 - p\\) La expresi\u00f3n de encima de estas l\u00edneas funciona para cualquiera que sea el valor de \\(p \\in [0, 1]\\) . Como seguro os habr\u00e9is dado cuenta, cuando \\(p = 0.5\\) nos encontramos ante una moneda normal o no trucada. Este hecho hace de esta expresi\u00f3n una expresi\u00f3n mucho m\u00e1s general, es decir, sirve para cualquier tipo de moneda.","title":"Monedas"},{"location":"math/maximum-likelihood-estimation-1/#independencia-de-sucesos","text":"Es imprescindible darse cuenta de que si hacemos varios lanzamientos de monedas, son todos sucesos independientes entre s\u00ed. Si lanzas una moneda y cae cara \u00bfcondiciona ese hecho a que en el siguiente lanzamiento vuelva a salir cara? La respuesta es no. Veamos ahora unos ejemplos de c\u00f3mo se calcula la probabilidad de varios lanzamientos. \u00bfCu\u00e1l es la probabilidad de obtener , tras 2 lanzamientos con una moneda normal? Al tratarse de sucesos independientes entre s\u00ed, tenemos que \\(P(\\) , \\() = P(\\) \\() \\cdot P(\\) \\() = 0.5 \\cdot 0.5 = 0.25\\) . Es interesante darse cuenta que en este tipo de ejercicios no nos importa el orden de las monedas, puesto que: \\(P(\\) , \\() = P(\\) \\() \\cdot P(\\) \\() = P(\\) \\() \\cdot P(\\) \\() = P(\\) , \\()\\) . \u00bfCu\u00e1l es la probabilidad de obtener esa misma secuencia sea cual sea la moneda utilizada? Tanto si consideramos que la moneda est\u00e1 trucada como que no, obtenemos que \\(P(\\) , \\() = P(\\) \\() \\cdot P(\\) \\() = (1 - p) \\cdot p.\\) Si sustituimos \\(p\\) por \\(0.5\\) obtenemos ex\u00e1ctamente el mismo valor de antes, el valor para una moneda normal: \\((1 - 0.5) \\cdot 0.5 = 0.5 \\cdot 0.5 = 0.25\\) . \u00bfCu\u00e1l es la probabilidad de obtener , , si \\(p = 0.1\\) ? \\(P(\\) , , \\() = P(\\) \\() \\cdot P(\\) \\() \\cdot P(\\) \\() = P(\\) \\()^3 = 0.1^3 = 0.001\\) \u00bfCu\u00e1l es la probabilidad de obtener , , si \\(p = 0.9\\) ? \\(P(\\) , , \\() = P(\\) \\()^3 = 0.9^3 = 0.729\\) S\u00e9 lo que est\u00e1is pensando, \"\u00a1qu\u00e9 preguntas m\u00e1s tontas me est\u00e1 haciendo!\". Pues s\u00ed, son ejercicios muy f\u00e1ciles, pero quiero que os fij\u00e9is bien en las dos \u00faltimas preguntas y me dig\u00e1is qu\u00e9 valor de \\(p\\) consigue una probabilidad m\u00e1s alta. Con \\(p = 0.1\\) se consigue \\(0.001\\) y con \\(p = 0.9\\) se consigue \\(0.729\\) . \u00bfHay alg\u00fan otro valor de \\(p\\) que consiga un valor m\u00e1s alto de probabilidad para obtener 3 caras? La respuesta es s\u00ed, con \\(p = 1\\) se consigue una probabilidad de \\(1\\) . Si calculamos la probabilidad de obtener 3 caras en funci\u00f3n del par\u00e1metro \\(p\\) obtenemos \\(P(\\) , , \\() = P(\\) \\()^3 = p^3\\) . Ahora que tenemos esa expresi\u00f3n, vamos a representarla en una gr\u00e1fica. Puesto que \\(p\\) es una probabilidad, el valor de ese par\u00e1metro se encuentra dentro del intervalo \\(p \\in [0, 1]\\) . Sobre la l\u00ednea he marcado 3 puntos, los valores de \\(p\\) que ya hemos calculado. Comprobamos claramente que el valor de probabilidad m\u00e1s alto se obtiene cuando \\(p = 1\\) , lo que confirma nuestro anterior c\u00e1lculo. Por comentar algo m\u00e1s de la gr\u00e1fica, diremos que seg\u00fan ella no es posible obtener 3 caras cuando \\(p = 0\\) puesto que la funci\u00f3n vale 0 al inicio. Esto tiene mucho sentido puesto que no es posible obtener 3 caras al lanzar 3 veces una moneda en la que nunca sale cara. window.addEventListener('load', function(){ JXG.Options.text.useMathJax = true; var board = JXG.JSXGraph.initBoard('jxgbox1', { boundingbox: [-0.1, 1.1, 1.1, -0.1], showNavigation: false, axis: true }); var graph = board.create('functiongraph', [function(p){ var n_caras = 3; var n_cruces = 0; var max = n_caras / (n_caras + n_cruces); return Math.pow(p, n_caras) * Math.pow(1 - p, n_cruces); }, 0, 1]); var p1 = board.create('point', [0.1, 0.001], { label: true, fixed: true, name: \"\\\\[p = 0.1\\\\]\", label: { position: 'top', offset: [-10, 20] } }); var p2 = board.create('point', [0.9, 0.729], { label: false, fixed: true, name: \"\\\\[p = 0.9\\\\]\", label: { position: 'top', offset: [-10, 20] } }); var p3 = board.create('point', [1, 1], { label: false, fixed: true, name: \"\\\\[p = 1\\\\]\", label: { position: 'top', offset: [-10, 20] } }); board.create('text', [1.00, 0.06, function() { return '\\\\[p\\\\]'; }], {fixed: true}); board.fullUpdate(); });","title":"Independencia de sucesos"},{"location":"math/maximum-likelihood-estimation-1/#otro-ejemplo","text":"Vamos a observar otro ejemplo distinto en el que tras tirar 10 veces una misma moneda obtenemos 8 caras y 2 cruces (recuerda que el orden no nos importa en absoluto, cualquier combinaci\u00f3n con 8 caras y 2 cruces tiene el mismo valor de probabilidad). A diferencia de antes, ahora en los resultados obtenidos encontramos tanto caras como cruces. \u00bfCu\u00e1l dir\u00edas que es el valor de \\(p\\) de dicha moneda? Posiblemente hayas realizado el c\u00e1lculo \\(p = \\frac{8 \\text{ caras}}{10 \\text{ lanzamientos}} = 0.8\\) . Pues lo cierto es que entre cualquier posible valor de \\(p\\) , el \\(0.8\\) es el valor m\u00e1s cre\u00edble, m\u00e1s veros\u00edmil, m\u00e1s plausible, m\u00e1s likelihood ... ll\u00e1malo como quieras. Si volvemos a representar la probabilidad en funci\u00f3n de \\(p\\) obtenemos la siguiente gr\u00e1fica: window.addEventListener('load', function(){ JXG.Options.text.useMathJax = true; var board = JXG.JSXGraph.initBoard('jxgbox2', { boundingbox: [-0.1, 1.1, 1.1, -0.1], showNavigation: false, axis: false, offsetX: 1 }); var yaxis = board.create('axis', [[0, 0], [0, 1]], { ticks: { insertTicks: true, drawLabels: false, minorTicks: 0 } }); var xaxis = board.create('axis', [[0, 0], [1, 0]], { ticks: { drawZero: true, minorTicks: 0, drawLabels: false } }); var xticks = board.create('ticks', [xaxis, [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]], { drawLabels: true, label : { offset: [-2.5, -17.4] } }); var n_caras = 8; var n_cruces = 2; var max = n_caras / (n_caras + n_cruces); var max_value = Math.pow(max, n_caras) * Math.pow(1 - max, n_cruces); var graph = board.create('functiongraph', [function (p) { return Math.pow(p, n_caras) * Math.pow(1 - p, n_cruces) / max_value; }, 0, 1]); var p3 = board.create('point', [max, 1], { showInfobox: false, label: false, fixed: true, name: \"(\" + max + \", \" + max_value.toExponential(2) + \")\" }); board.create('text',[0.1, 0.7, function() { return String.raw`\\[p ^ {n_{caras}} \\cdot (1 - p) ^ {n_{cruces}}\\]`; }], { fontSize: 24, highlightStrokeOpacity: 1, highlightFillOpacity: 1 }); board.create('text',[0.1, 0.5, function() { return String.raw`\\[n_{caras} = 8\\]`; }], { fontSize: 24, highlightStrokeOpacity: 1, highlightFillOpacity: 1 }); board.create('text',[0.1, 0.3, function() { return String.raw`\\[n_{cruces} = 2\\]`; }], { fontSize: 24, highlightStrokeOpacity: 1, highlightFillOpacity: 1 }); board.create('text',[1.06, -0.03, function() { return '\\\\[p\\\\]'; }], {fixed: true}); board.fullUpdate(); }); El valor \\(p = 0.8\\) es el m\u00e1s veros\u00edmil, pero al fin y al cabo, en 10 lanzamientos de una moneda normal ( \\(p = 0.5\\) ) puede pasar que nos salgan 8 caras. Es raro, pero puede pasar. Digamos que cambiamos el n\u00famero de lanzamientos por 100 y obtenemos 80 caras y 20 cruces, \u00bfcu\u00e1l dir\u00edas que es el valor de \\(p\\) ahora? Al igual que antes, \\(p = \\frac{80}{100} = 0.8\\) . Si representamos gr\u00e1ficamente la probabilidad en funci\u00f3n de \\(p\\) obtenemos algo muy similar a la \u00faltima gr\u00e1fica, solo que ahora el pico es mucho m\u00e1s estrecho, lo que podemos interpretar como que es menos probable que tirando una moneda normal se obtengan esos resultados. Antes dec\u00edamos que era raro obtener 8 caras de 10 lanzamientos con una moneda normal, ahora decimos que es muy muy muy muy raro, por no decir imposible, obtener 80 caras de 100 lanzamientos con una moneda normal (comprueba la altura de la curva de la siguiente gr\u00e1fica en \\(p = 0.5\\) con la de la gr\u00e1fica anterior). window.addEventListener('load', function(){ var board = JXG.JSXGraph.initBoard('jxgbox3', { boundingbox: [-0.1, 1.1, 1.1, -0.1], showNavigation: false, axis: false, offsetX: 1 }); var yaxis = board.create('axis', [[0, 0], [0, 1]], { ticks: { insertTicks: true, drawLabels: false, minorTicks: 0 } }); var xaxis = board.create('axis', [[0, 0], [1, 0]], { ticks: { drawZero: true, minorTicks: 0, drawLabels: false } }); var xticks = board.create('ticks', [xaxis, [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]], { drawLabels: true, label : { offset: [-2.5, -17.4] } }); var n_caras = 80; var n_cruces = 20; var max = n_caras / (n_caras + n_cruces); var max_value = Math.pow(max, n_caras) * Math.pow(1 - max, n_cruces); var graph = board.create('functiongraph', [function (p) { return Math.pow(p, n_caras) * Math.pow(1 - p, n_cruces) / max_value; }, 0, 1]); var p3 = board.create('point', [max, 1], { showInfobox: false, label: false, fixed: true, name: \"(\" + max + \", \" + max_value.toExponential(2) + \")\" }); board.create('text',[0.1, 0.7, function() { return String.raw`\\[p ^ {n_{caras}} \\cdot (1 - p) ^ {n_{cruces}}\\]`; }], { fontSize: 24, highlightStrokeOpacity: 1, highlightFillOpacity: 1 }); board.create('text',[0.1, 0.5, function() { return String.raw`\\[n_{caras} = 80\\]`; }], { fontSize: 24, highlightStrokeOpacity: 1, highlightFillOpacity: 1 }); board.create('text',[0.1, 0.3, function() { return String.raw`\\[n_{cruces} = 20\\]`; }], { fontSize: 24, highlightStrokeOpacity: 1, highlightFillOpacity: 1 }); board.create('text',[1.06, -0.03, function() { return '\\\\[p\\\\]'; }], {fixed: true}); board.fullUpdate(); }); Como hab\u00e9is podido observar, el valor de \\(p\\) que consigue la probabilidad m\u00e1s alta de una secuencia de lanzamientos se puede obtener con \\[\\dfrac{\\text{# caras}}{\\text{# lanzamientos}}\\] \u00bfDe d\u00f3nde sale esa f\u00f3rmula? Esa divisi\u00f3n que puede resultar muy natural y que usamos a menudo sin plantearnos de d\u00f3nde ha salido, se obtiene gracias al MLE (en la segunda parte de este art\u00edculo veremos c\u00f3mo se llega a ella). Por lo tanto, MLE nos permite obtener el valor de un par\u00e1metro (en nuestro caso \\(p\\) ) para que tengan lugar de forma m\u00e1s probable un conjunto de observaciones (resultados de los lanzamientos de una moneda). Muchos problemas de estad\u00edstica nos dicen: tenemos una moneda con \\(P(\\) \\() = p\\) , \u00bfcu\u00e1l es la probabilidad de obtener \\(X\\) secuencia de lanzamientos con ella?. MLE se utiliza para dar respuesta a otra pregunta ligeramente distinta: teniendo una secuencia de lanzamientos \\(X\\) , \u00bfcu\u00e1l es el valor de \\(p\\) que maximiza la probabilidad de obtener dicha secuencia?","title":"Otro ejemplo"},{"location":"math/maximum-likelihood-estimation-1/#pruebalo-tu-mismo","text":"Os he preparado un peque\u00f1o gr\u00e1fico interactivo que os ayudar\u00e1 a comprender las likelihood functions . En la parte superior del gr\u00e1fico hay un par de barras deslizantes que puedes cambiar a tu antojo. La primera de ellas corresponde al n\u00famero de veces que la moneda lanzada ha ca\u00eddo cara y la segunda de ellas al n\u00famero de veces que ha ca\u00eddo cruz. La funci\u00f3n representada no es m\u00e1s que la probabilidad en funci\u00f3n de \\(p\\) de obtener una serie de lanzamientos con ese n\u00famero de caras y cruces. Un punto rojo indica el m\u00e1ximo de la curva. window.addEventListener('load', function(){ var board = JXG.JSXGraph.initBoard('jxgbox4', { boundingbox: [-0.1, 1.3, 1.1, -0.1], showNavigation: false, axis: false }); var yaxis = board.create('axis', [[0, 0], [0, 1]], { ticks: { insertTicks: true, drawLabels: false, minorTicks: 0 } }); var xaxis = board.create('axis', [[0, 0], [1, 0]], { ticks: { drawZero: true, minorTicks: 0, drawLabels: false } }); var xticks = board.create('ticks', [xaxis, [0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1]], { fixed: true, drawLabels: true, label : { offset: [-2.5, -17.4] } }); var slider_caras = board.create('slider', [[0.1,1.2],[0.7,1.2],[0, 5, 10]], { //name: String.raw`\\[n_{caras}\\]`, name: 'n_{caras}', snapWidth: 1, precision: 0 }); var slider_cruces = board.create('slider', [[0.1,1.1],[0.7,1.1],[0, 5, 10]], { //name: String.raw`\\[n_{cruces}\\]`, name: 'n_{cruces}', snapWidth: 1, precision: 0 }); var p3 = board.create('point', [0.5, 1], { showInfobox: false, fixed: true, label: { position: 'top', offsets: [-50, 10] } }); var graph = board.create('functiongraph', [function(p){ var n_caras = slider_caras.Value(); var n_cruces = slider_cruces.Value(); var max = n_caras / (n_caras + n_cruces); var max_value = Math.pow(max, n_caras) * Math.pow(1 - max, n_cruces); if (p == 0) { // Importante para actualizar el punto m\u00e1ximo solo una vez y no cada punto de la curva. p3.setName(\"(\" + max.toFixed(2) + \", \" + max_value.toExponential(2) + \")\"); p3.setPosition(JXG.COORDS_BY_USER, [max, 1]); } return Math.pow(p, n_caras) * Math.pow(1 - p, n_cruces) / max_value; }, 0, 1]); board.fullUpdate(); });","title":"Pru\u00e9balo t\u00fa mismo"},{"location":"math/maximum-likelihood-estimation-1/#algunas-observaciones","text":"Antes de terminar me gustar\u00eda aclarar algunas cosas que quiz\u00e1s respondan a dudas que te hayan surgido conforme le\u00edas el art\u00edculo. Puede que est\u00e9s pensando si el \u00e1rea que se encuentra bajo la curva (integral) de la funci\u00f3n likelihood debe de sumar 1. Eso no ocurre pr\u00e1cticamente nunca. En el ejemplo interactivo, parece que la funci\u00f3n siempre tenga su m\u00e1ximo a la misma altura, eso es debido a que se ha llevado a cabo un proceso de normalizaci\u00f3n con la idea de poder observar perfectamente la curva entera sin tener que hacer zoom en la figura. Cuanto mayor es el n\u00famero de lanzamientos, la altura m\u00e1xima de la curva disminuye a valores realmente bajos (con 10 caras y 10 cruces el m\u00e1ximo es del orden de \\(10^{-6}\\) ). En la pr\u00e1ctica, el valor de la funci\u00f3n no importa, s\u00f3lo nos importa d\u00f3nde se encuentra el m\u00e1ximo. Es por dicha raz\u00f3n por las que no se muestran las unidades del eje \\(y\\) . \u00bfHas jugado ya con el ejemplo interactivo? Si no lo has hecho te recomiendo por lo menos llevar a cabo alguna de estas pruebas. Pon a 0 las dos barras deslizantes. Despu\u00e9s selecciona una de ellas y ve aument\u00e1ndola poco a poco. \u00bfQu\u00e9 observas? Pon a 0 las dos barras deslizantes. Despu\u00e9s incrementa al mismo tiempo ambas barras. \u00bfQu\u00e9 observas? F\u00edjate tambi\u00e9n en el valor de probabilidad del punto m\u00e1ximo (la coordenada \\(y\\) del punto rojo) \u00bfQu\u00e9 le pasa conforme aumenta el n\u00famero total de lanzamientos?","title":"Algunas observaciones"},{"location":"math/maximum-likelihood-estimation-1/#para-saber-mas","text":"Creo que con lo visto en este art\u00edculo ha quedado claro cu\u00e1l es el cometido del MLE. Para explicarlo no hemos hecho uso de expresiones matem\u00e1ticas complejas, solo estad\u00edstica b\u00e1sica. En la segunda parte de este art\u00edculo introduciremos notaci\u00f3n matem\u00e1tica y veremos en acci\u00f3n esta t\u00e9cnica de estimaci\u00f3n de par\u00e1metros. El ejemplo ser\u00e1 la derivaci\u00f3n matem\u00e1tica necesaria para llegar a obtener porqu\u00e9 el valor de \\(p\\) que m\u00e1s probabilidad consigue en cualquier secuencia de lanzamientos es \\(\\frac{\\text{# caras}}{\\text{# lanzamientos}}\\) . \u00a1Nos vemos en la segunda parte!","title":"Para saber m\u00e1s"},{"location":"math/maximum-likelihood-estimation-1/#creditos","text":"Las im\u00e1genes de las monedas son una modificaci\u00f3n propia de varios ficheros descargados desde Freepik . Las gr\u00e1ficas interactivas han sido hechas con la ayuda de la librer\u00eda JSXGraph . .coin, .head, .tail { background-size: cover; display: inline-block; height: 2em; width: 2em; vertical-align: middle; margin-top: 1px; } .head { background-image: url(\"/assets/images/2018_10_18_coin_head.png\"); } .tail { background-image: url(\"/assets/images/2018_10_18_coin_tail.png\"); }","title":"Cr\u00e9ditos"},{"location":"math/maximum-likelihood-estimation-2/","tags":["Statistics"],"text":"\ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 2 En esta segunda parte vamos a dar por hecho que se conoce el concepto de MLE que fue visto en detalle en la primera parte de esta serie de dos art\u00edculos. Esta segunda parte es mucho m\u00e1s intensa y emocionante que la anterior. En la primera parte se explica el concepto de forma gr\u00e1fica y con un ejemplo interactivo, pero una vez eso se tiene claro llega el momento de introducir notaci\u00f3n matem\u00e1tica \ud83d\ude2c. Tal y como dijimos en el anterior at\u00edculo, hoy demostraremos el porqu\u00e9 la divisi\u00f3n \\(\\frac{\\text{# caras}}{\\text{# lanzamientos}}\\) nos devuelve el valor del par\u00e1metro \\(p\\) m\u00e1s likelihood en cualquier secuencia de lanzamientos de una moneda. Requisitos Nociones muy b\u00e1sicas de estad\u00edstica, como saber calcular la media de una muestra. Conocer el concepto del Maximum Likelihood Estimation (MLE). Puedes aprenderlo sin salir de este blog en la primera parte. Saber lo que es una derivada y c\u00f3mo usarla para minimizar una funci\u00f3n. M\u00e1s monedas Estuvimos trabajando con monedas y seguiremos con ellas durante este art\u00edculo. En esta segunda parte vamos a hacer un esfuerzo por obtener expresiones generales, que sirven para cualquier tipo de moneda y para cualquier resultado obtenido por dicha moneda. No os quiero asustar con palabrer\u00eda, vayamos paso a paso. En primer lugar llamaremos \\(X\\) al resultado obtenido tras lanzar \\(N\\) monedas, es decir, \\(X\\) es una lista con caras y cruces. La primera cara o cruz corresponde al primer lanzamiento y as\u00ed sucesivamente hasta el lanzamiento \\(N\\) . \\(X = (X_1, X_2, \\dots, X_N)\\) Diremos que \\(X_i = 1\\) cuando haya salido cara en el lanzamiento \\(i\\) . Del mismo modo, diremos que \\(X_i = 0\\) cuando el lanzamiento \\(i\\) haya sido cruz. En ambos casos \\(i = 1, 2, \\dots, N\\) . Para que esto quede claro vamos a ver un ejemplo. Suponed que lanzamos una moneda 3 veces y obtenemos: , , . \u00bfCu\u00e1l es el vector \\(X\\) asociado a dicha secuencia de lanzamientos? Muy sencillo: \\(X = (1, 1, 0)\\) . Hagamos un peque\u00f1o repaso a las probabilidades de obtener cara o cruz. \u00bfCu\u00e1l es la probabilidad de obtener cara? \\(P(\\) \\() = P(X_i = 1) = p\\) \u00bfCu\u00e1l es la probabilidad de obtener cruz? \\(P(\\) \\() = P(X_i = 0) = 1 - p\\) A modo de informaci\u00f3n extra, este tipo de distribuci\u00f3n de probabilidad se le conoce como distribuci\u00f3n de Bernoulli . Por lo tanto, en este art\u00edculo nos vamos a centrar en estimar el par\u00e1metro de una distribuci\u00f3n de Bernoulli , par\u00e1metro que en nuestro ejemplo con monedas hemos llamado \\(p\\) . Yendo un poco m\u00e1s lejos \u00bfCu\u00e1l es la probabilidad de obtener \\(X_i\\) ? \u00bfC\u00f3mo? Me refiero a cu\u00e1l es la probabilidad de que en un lanzamiento \\(i\\) (es decir, en cualquier lanzamiento) se consiga el resultado obtenido. Posiblemente me dir\u00e9is: pues eso depende del resultado obtenido. No os equivoc\u00e1is. Como ya hemos dicho antes, si \\(X_i = 1\\) entonces la probabilidad es \\(p\\) y si \\(X_i = 0\\) la probabilidad es \\(1 - p\\) . Vamos a juntar eso en una sola expresi\u00f3n: \\[P(X_i) = p^{X_i}(1 - p)^{1 - X_i}\\] En esa sola l\u00ednea se resume la probabilidad de cada lanzamiento. Hemos conseguido expresar la probabilidad de obtener un lanzamiento dado sin importarnos realmente cu\u00e1l es el resultado de dicho lanzamiento. Podemos verlo como dos factores, por un lado \\(p^{X_i}\\) y por otro lado \\((1 - p)^{1 - X_i}\\) . Cuando \\(X_i = 1\\) , entonces el segundo factor se neutraliza debido a que el exponente pasa a valer 0 (cualquier n\u00famero elevado a 0 es 1, lo que no modifica la multiplicaci\u00f3n). Cuando \\(X_i = 0\\) , es el primer factor el que se neutraliza. Por lo tanto, al sustituir \\(X_i\\) por su valor se obtiene ex\u00e1ctamente el mismo valor de probabilidad que antes. \\[ \\require{cancel} \\begin{align} P(X_i = 1) &= p ^ 1 \\cancelto{1}{(1 - p) ^ {1 - 1}} = p\\\\ P(X_i = 0) &= \\cancelto{1}{p^{0}} (1 - p) ^ {1 - 0} = 1 - p \\end{align} \\] Las probabilidades dependen del valor de \\(p\\) , es decir, est\u00e1n condicionadas al valor de ese par\u00e1metro. Es por ello que muchas veces se utiliza la sintaxis propia de las probabilidades condicionales \\(P(X_i\\,\\vert\\,p)\\) . La forma de escribirlo depende bastante del autor. Probabilidad conjunta Ahora que sabemos cu\u00e1l es la probabilidad de cada uno de los lanzamientos podemos hallar la probabilidad de obtener todos los lanzamientos uno detr\u00e1s de otro, es decir \\(P(X\\ \\vert\\ p)\\) . Sabemos que los lanzamientos son eventos independientes, por lo que para obtener el valor de probabilidad de todos los lanzamientos juntos basta con multiplicar la probabilidad de cada uno de los lanzamientos (tal y como hicimos en los ejercicios de ejemplo de la primera parte . Matem\u00e1ticamente podemos expresar el valor de probabilidad conjunta utilizando el productorio \\(\\prod\\) de la siguiente manera \\[P(X\\ \\vert\\ p) = \\prod_{i = 1}^{N} P(X_i\\ \\vert\\ p) = \\prod_{i = 1}^{N} p^{X_i}(1 - p)^{1 - X_i}\\] Recapitulamos : hemos encontrado la forma de expresar en una sola ecuaci\u00f3n la probabilidad de obtener un lanzamiento concreto sin importarnos del resultado obtenido en dicho lanzamiento. Ahora hemos hallado la probabilidad de obtener un conjunto de lanzamientos. Nos fijamos que esa expresi\u00f3n es muy general, no nos importan ni saber cu\u00e1l es el n\u00famero de lanzamientos, ni saber los resultados de dichos lanzamientos y tampoco el valor de \\(p\\) asociado a la moneda utilizada. Tal y como ven\u00edamos comentando en el anterior art\u00edculo, lo que realmente nos interesa es, dado un conjunto de lanzamientos \\(X\\) , obtener el valor del par\u00e1metro \\(p\\) que maximice la probabilidad de obtener dicha \\(X\\) . Para obtener ese valor debemos de maximizar \\(P(X\\ \\vert\\ p)\\) . Funci\u00f3n Likelihood Vamos a definir una funci\u00f3n que nos de el valor de probabilidad de \\(X\\) en funci\u00f3n del valor del par\u00e1metro \\(p\\) . Al maximizar dicha funci\u00f3n obtendremos el valor de \\(p\\) que mayor probabilidad obtene en esos datos. Esa funci\u00f3n se conoce como la funci\u00f3n likelihood y se representa como \\[L(p;\\ X) = P(X\\ \\vert\\ p) = \\prod_{i = 1}^{N} P(X_i\\ \\vert\\ p).\\] Los dos puntos separan las variables de los par\u00e1metros fijos. Los valores \\(X_i\\) no son conocidos pero son fijos, es decir, que nosotros queremos maximizar el valor del parametro \\(p\\) usando unos valores de \\(X_i\\) que no cambiar\u00e1n durante el proceso (para m\u00e1s informaci\u00f3n mirar esta pregunta de math.stackexchange ). La forma de designar esta funci\u00f3n var\u00eda bastante de un autor a otro. En muchos textos en lugar de la letra \\(L\\) se utiliza \\(\\mathcal{L}\\) para designar a la funci\u00f3n likelihood . Personalmente prefiero reservar \\(\\mathcal{L}\\) para los multiplicadores de Lagrange , pero vamos, que no es algo relevante. Otros simplemente escriben \\(L(p)\\) dando por hecho la existencia de \\(X\\) . Como deber\u00edas de saber para entender lo que viene a continuaci\u00f3n, a la hora de querer maximizar una funci\u00f3n lo m\u00e1s com\u00fan es utilizar la primera derivada e igualarla a 0. Derivar \\(L(p;\\ X)\\) con ese productorio... complicado. Ser\u00eda ideal poder cambiar ese productorio por otra expresi\u00f3n mucho m\u00e1s sencilla de derivar. Eso se consigue de una forma muy r\u00e1pida, aplicando el logaritmo a la funci\u00f3n likelihood . La funci\u00f3n likelihood devuelve una probabilidad, por lo que se encuentra acotada entre 0 y 1. Vamos a recordar la forma de la funci\u00f3n logaritmo . window.addEventListener('load', function() { JXG.Options.text.useMathJax = true; var board = JXG.JSXGraph.initBoard('jxgbox1', { boundingbox: [-1, 2.0, 5.0, -2], showNavigation: false, axis: true, zoom: { factorX: 1.25, factorY: 1.25, wheel: true, needshift: false, eps: 0.1 }, pan: { needshift: false } }); var graph = board.create('functiongraph', [function(x) { return Math.log(x); }]); board.create('text',[3, 1, function() { return '\\\\[\\\\ln\\\\ x\\\\]'; }], { fixed: true, fontSize: 20 }); board.fullUpdate(); }); Se observa que se trata de una funci\u00f3n mon\u00f3tona creciente, es decir, que la curva que representa la funci\u00f3n nunca va para abajo. Para los m\u00e1s curiosos, el \"nunca va para abajo\" se expresa matem\u00e1ticamente con \\(\\forall x \\le y, f(x) \\le f(y)\\) (para m\u00e1s informaci\u00f3n ver funciones mon\u00f3tonas en Wikipedia ). Esto quiere decir que, si aplicamos el logaritmo a la funci\u00f3n \\(L\\) , no cambiar\u00e1 el m\u00e1ximo de la funci\u00f3n. Dicha transformaci\u00f3n nos permitir\u00e1 derivar de forma m\u00e1s sencilla y obtener el mismo m\u00e1ximo que si maximiz\u00e1ramos el productorio original. Es importante darse cuenta de que los valores de la funci\u00f3n cambiar\u00edan (ya no estar\u00edan expresando la probabilidad de \\(X\\) ), pero lo importante es que el m\u00e1ximo es el mismo en las dos funciones. Tras aplicarle el logaritmo, la funci\u00f3n likelihood se suele designar con \\(\\ell\\) y se le llama log-likelihood . Matem\u00e1ticamente se define como \\[\\ell(p;\\ X) = \\ln(L(p;\\ X)) = \\sum_{i = 1}^{N} \\ln P(X_i\\ \\vert\\ p).\\] No solo cambiamos el productorio por un sumatorio, sino que tambi\u00e9n eliminamos el producto que encontr\u00e1bamos al calcular la probabilidad de una sola moneda. \\[ \\begin{align} \\ln P(X_i\\ \\vert\\ p) &= \\ln p^{X_i} + \\ln (1 - p)^{1 - X_i}\\\\ &= X_i \\ln p + (1 - X_i) \\ln (1 - p) \\end{align} \\] En esa \u00faltima l\u00ednea hemos hecho uso de la propiedad que dice \\(\\ln a^b = b \\ln a\\) . La funci\u00f3n completa quedar\u00eda de la siguiente manera: \\[ \\ell(p;\\ X) = \\sum_{i = 1}^{N} \\left[ X_i \\ln p + (1 - X_i) \\ln (1 - p) \\right]. \\] Maximicemos pues la funci\u00f3n \\(\\ell(p;\\ X)\\) igualando a 0 la primera derivada, es decir, \\(\\dfrac{d \\ell(p)}{d p} = 0\\) . \\[ \\require{cancel} \\begin{align} \\dfrac{d \\ell(p;\\ X)}{d p} &= \\sum_{i = 1}^{N} \\left[ \\dfrac{X_i}{p} + \\dfrac{1 - X_i}{1 - p} \\left(\\dfrac{d (1 - p)}{d p}\\right) \\right] = \\\\ &= \\sum_{i = 1}^{N} \\left[ \\dfrac{X_i}{p} + \\dfrac{1 - X_i}{1 - p} (-1) \\right] = \\\\ &= \\sum_{i = 1}^{N} \\left[ \\dfrac{X_i}{p} - \\dfrac{1 - X_i}{1 - p} \\right] = \\\\ &= \\sum_{i = 1}^{N} \\left[ (1 - p) X_i - p (1 - X_i) \\right] =\\\\ &= \\sum_{i = 1}^{N} \\left[ X_i - \\cancel{X_i p} - p + \\cancel{X_i p} \\right] = \\\\ &= \\sum_{i = 1}^{N} \\left[ X_i - p \\right] = \\\\ &= - N p + \\sum_{i = 1}^{N} X_i = 0\\\\ \\end{align} \\] Por si alguien se ha perdido durante la derivaci\u00f3n aclarar\u00e9 las 2 cosas que m\u00e1s problemas pueden dar. \\(\\dfrac{d \\ln f(x)}{d x} = \\dfrac{1}{f(x)} f'(x)\\) , siendo \\(f\\) una funci\u00f3n cualquiera. \\(\\sum_{i = 1}^{N} c = Nc\\) siendo \\(c\\) una constante cualquiera. En la derivaci\u00f3n el par\u00e1metro \\(p\\) no cambia conforme cambiamos de lanzamiento \\(i\\) , por lo que es una constante dentro de ese sumatorio. Llegados a este punto solo queda despejar \\(p\\) y obtenemos que \\[p = \\dfrac{1}{N} \\sum_{i = 1}^{N} X_i\\text{.}\\] \u00bfOs suena este resultado? Seguro que s\u00ed. Vamos a escribirlo utilizando palabras m\u00e1s amigables. \\[p = \\dfrac{\\text{n\u00famero de caras}}{\\text{n\u00famero de lanzamientos}}.\\] Se trata ex\u00e1ctamente de la misma expresi\u00f3n. El sumatorio cuenta el n\u00famero de caras puesto que \\(X_i = 1\\) cuando el lanzamiento \\(i\\) ha salido cara y \\(X_i = 0\\) cuando ha sido cruz. El n\u00famero de lanzamientos es \\(N\\) . Debido a que el valor del par\u00e1metro \\(p\\) es una estimaci\u00f3n y no es su valor real (no sabemos el valor real de la moneda que ha generado dichos lanzamientos) se le suele poner un sombrerito encima \\(\\hat{p}\\) . Por lo tanto finalmente tenemos que \\(\\hat{p} = \\dfrac{1}{N} \\sum_{i = 1}^{N} X_i\\text{,}\\) lo que traducido a palabras significa que el valor de \\(p\\) estimado con el MLE no es otra cosa que el n\u00famero de caras entre el n\u00famero total de lanzamientos. \u00bfQu\u00e9 hemos hecho? A modo de resumen voy a exponer los pasos seguidos para obtener el resultado final. En primer lugar hemos definido \\(X\\) como una serie de lanzamientos de una moneda. Hemos obtenido una expresi\u00f3n que nos permite hallar la probabilidad de un lanzamiento dado, \\(P(X_i\\ \\vert\\ p)\\) . Multiplicando el valor de probabilidad de cada moneda obtenemos la probabilidad conjunta de todos los lanzamientos, \\(P(X\\ \\vert\\ p)\\) . Hemos creado una funci\u00f3n, likelihood function , que devuelve la probabilidad conjunta en funci\u00f3n de \\(p\\) , \\(L(p;\\ X)\\) . Con el objetivo de maximizar esa funci\u00f3n le hemos aplicado el logaritmo obteniendo as\u00ed la funci\u00f3n log-likelihood , \\(\\ell(p;\\ X)\\) . Igualamos la primera derivada de esa funci\u00f3n a \\(0\\) y despejamos \\(p\\) para obtener as\u00ed la estimaci\u00f3n, es decir, \\(\\hat{p}\\) . A modo de pr\u00e1ctica podr\u00edas intentar repetir t\u00fa solo el proceso y comprobar que has llegado al mismo resultado. Deja pasar unos d\u00edas para que se te olvide lo que acabas de leer e int\u00e9ntalo t\u00fa mismo a ver si lo sacas (estoy seguro de que s\u00ed :). Si encuentras cualquier fallo, ya sea hortogr\u00e1fico, algo mal explicado, alg\u00fan n\u00famero que no est\u00e1 donde tiene que estar... lo que sea, d\u00e9jame un comentario. Cualquier duda que tengas tambi\u00e9n es bienvenida al tabl\u00f3n de comentarios. Por cierto, lo de \"hortogr\u00e1fico\" era broma, solo quer\u00eda comprobar si estabas atento \ud83d\ude1c. Cr\u00e9ditos Las im\u00e1genes de las monedas son una modificaci\u00f3n propia de varios ficheros descargados desde Freepik . La gr\u00e1fica del logaritmo ha sido hecha con la ayuda de la librer\u00eda JSXGraph . .coin, .head, .tail { background-size: cover; display: inline-block; height: 2em; width: 2em; vertical-align: middle; margin-top: 1px; } .head { background-image: url(\"/assets/images/2018_10_18_coin_head.png\"); } .tail { background-image: url(\"/assets/images/2018_10_18_coin_tail.png\"); } .MathJax_Display > span.MathJax { overflow-y: hidden; overflow-x: auto; display: block; text-align: center; outline: 0; }","title":"\ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 2"},{"location":"math/maximum-likelihood-estimation-2/#maximum-likelihood-estimation-parte-2","text":"En esta segunda parte vamos a dar por hecho que se conoce el concepto de MLE que fue visto en detalle en la primera parte de esta serie de dos art\u00edculos. Esta segunda parte es mucho m\u00e1s intensa y emocionante que la anterior. En la primera parte se explica el concepto de forma gr\u00e1fica y con un ejemplo interactivo, pero una vez eso se tiene claro llega el momento de introducir notaci\u00f3n matem\u00e1tica \ud83d\ude2c. Tal y como dijimos en el anterior at\u00edculo, hoy demostraremos el porqu\u00e9 la divisi\u00f3n \\(\\frac{\\text{# caras}}{\\text{# lanzamientos}}\\) nos devuelve el valor del par\u00e1metro \\(p\\) m\u00e1s likelihood en cualquier secuencia de lanzamientos de una moneda.","title":"\ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 2"},{"location":"math/maximum-likelihood-estimation-2/#requisitos","text":"Nociones muy b\u00e1sicas de estad\u00edstica, como saber calcular la media de una muestra. Conocer el concepto del Maximum Likelihood Estimation (MLE). Puedes aprenderlo sin salir de este blog en la primera parte. Saber lo que es una derivada y c\u00f3mo usarla para minimizar una funci\u00f3n.","title":"Requisitos"},{"location":"math/maximum-likelihood-estimation-2/#mas-monedas","text":"Estuvimos trabajando con monedas y seguiremos con ellas durante este art\u00edculo. En esta segunda parte vamos a hacer un esfuerzo por obtener expresiones generales, que sirven para cualquier tipo de moneda y para cualquier resultado obtenido por dicha moneda. No os quiero asustar con palabrer\u00eda, vayamos paso a paso. En primer lugar llamaremos \\(X\\) al resultado obtenido tras lanzar \\(N\\) monedas, es decir, \\(X\\) es una lista con caras y cruces. La primera cara o cruz corresponde al primer lanzamiento y as\u00ed sucesivamente hasta el lanzamiento \\(N\\) . \\(X = (X_1, X_2, \\dots, X_N)\\) Diremos que \\(X_i = 1\\) cuando haya salido cara en el lanzamiento \\(i\\) . Del mismo modo, diremos que \\(X_i = 0\\) cuando el lanzamiento \\(i\\) haya sido cruz. En ambos casos \\(i = 1, 2, \\dots, N\\) . Para que esto quede claro vamos a ver un ejemplo. Suponed que lanzamos una moneda 3 veces y obtenemos: , , . \u00bfCu\u00e1l es el vector \\(X\\) asociado a dicha secuencia de lanzamientos? Muy sencillo: \\(X = (1, 1, 0)\\) . Hagamos un peque\u00f1o repaso a las probabilidades de obtener cara o cruz. \u00bfCu\u00e1l es la probabilidad de obtener cara? \\(P(\\) \\() = P(X_i = 1) = p\\) \u00bfCu\u00e1l es la probabilidad de obtener cruz? \\(P(\\) \\() = P(X_i = 0) = 1 - p\\) A modo de informaci\u00f3n extra, este tipo de distribuci\u00f3n de probabilidad se le conoce como distribuci\u00f3n de Bernoulli . Por lo tanto, en este art\u00edculo nos vamos a centrar en estimar el par\u00e1metro de una distribuci\u00f3n de Bernoulli , par\u00e1metro que en nuestro ejemplo con monedas hemos llamado \\(p\\) .","title":"M\u00e1s monedas"},{"location":"math/maximum-likelihood-estimation-2/#yendo-un-poco-mas-lejos","text":"\u00bfCu\u00e1l es la probabilidad de obtener \\(X_i\\) ? \u00bfC\u00f3mo? Me refiero a cu\u00e1l es la probabilidad de que en un lanzamiento \\(i\\) (es decir, en cualquier lanzamiento) se consiga el resultado obtenido. Posiblemente me dir\u00e9is: pues eso depende del resultado obtenido. No os equivoc\u00e1is. Como ya hemos dicho antes, si \\(X_i = 1\\) entonces la probabilidad es \\(p\\) y si \\(X_i = 0\\) la probabilidad es \\(1 - p\\) . Vamos a juntar eso en una sola expresi\u00f3n: \\[P(X_i) = p^{X_i}(1 - p)^{1 - X_i}\\] En esa sola l\u00ednea se resume la probabilidad de cada lanzamiento. Hemos conseguido expresar la probabilidad de obtener un lanzamiento dado sin importarnos realmente cu\u00e1l es el resultado de dicho lanzamiento. Podemos verlo como dos factores, por un lado \\(p^{X_i}\\) y por otro lado \\((1 - p)^{1 - X_i}\\) . Cuando \\(X_i = 1\\) , entonces el segundo factor se neutraliza debido a que el exponente pasa a valer 0 (cualquier n\u00famero elevado a 0 es 1, lo que no modifica la multiplicaci\u00f3n). Cuando \\(X_i = 0\\) , es el primer factor el que se neutraliza. Por lo tanto, al sustituir \\(X_i\\) por su valor se obtiene ex\u00e1ctamente el mismo valor de probabilidad que antes. \\[ \\require{cancel} \\begin{align} P(X_i = 1) &= p ^ 1 \\cancelto{1}{(1 - p) ^ {1 - 1}} = p\\\\ P(X_i = 0) &= \\cancelto{1}{p^{0}} (1 - p) ^ {1 - 0} = 1 - p \\end{align} \\] Las probabilidades dependen del valor de \\(p\\) , es decir, est\u00e1n condicionadas al valor de ese par\u00e1metro. Es por ello que muchas veces se utiliza la sintaxis propia de las probabilidades condicionales \\(P(X_i\\,\\vert\\,p)\\) . La forma de escribirlo depende bastante del autor.","title":"Yendo un poco m\u00e1s lejos"},{"location":"math/maximum-likelihood-estimation-2/#probabilidad-conjunta","text":"Ahora que sabemos cu\u00e1l es la probabilidad de cada uno de los lanzamientos podemos hallar la probabilidad de obtener todos los lanzamientos uno detr\u00e1s de otro, es decir \\(P(X\\ \\vert\\ p)\\) . Sabemos que los lanzamientos son eventos independientes, por lo que para obtener el valor de probabilidad de todos los lanzamientos juntos basta con multiplicar la probabilidad de cada uno de los lanzamientos (tal y como hicimos en los ejercicios de ejemplo de la primera parte . Matem\u00e1ticamente podemos expresar el valor de probabilidad conjunta utilizando el productorio \\(\\prod\\) de la siguiente manera \\[P(X\\ \\vert\\ p) = \\prod_{i = 1}^{N} P(X_i\\ \\vert\\ p) = \\prod_{i = 1}^{N} p^{X_i}(1 - p)^{1 - X_i}\\] Recapitulamos : hemos encontrado la forma de expresar en una sola ecuaci\u00f3n la probabilidad de obtener un lanzamiento concreto sin importarnos del resultado obtenido en dicho lanzamiento. Ahora hemos hallado la probabilidad de obtener un conjunto de lanzamientos. Nos fijamos que esa expresi\u00f3n es muy general, no nos importan ni saber cu\u00e1l es el n\u00famero de lanzamientos, ni saber los resultados de dichos lanzamientos y tampoco el valor de \\(p\\) asociado a la moneda utilizada. Tal y como ven\u00edamos comentando en el anterior art\u00edculo, lo que realmente nos interesa es, dado un conjunto de lanzamientos \\(X\\) , obtener el valor del par\u00e1metro \\(p\\) que maximice la probabilidad de obtener dicha \\(X\\) . Para obtener ese valor debemos de maximizar \\(P(X\\ \\vert\\ p)\\) .","title":"Probabilidad conjunta"},{"location":"math/maximum-likelihood-estimation-2/#funcion-likelihood","text":"Vamos a definir una funci\u00f3n que nos de el valor de probabilidad de \\(X\\) en funci\u00f3n del valor del par\u00e1metro \\(p\\) . Al maximizar dicha funci\u00f3n obtendremos el valor de \\(p\\) que mayor probabilidad obtene en esos datos. Esa funci\u00f3n se conoce como la funci\u00f3n likelihood y se representa como \\[L(p;\\ X) = P(X\\ \\vert\\ p) = \\prod_{i = 1}^{N} P(X_i\\ \\vert\\ p).\\] Los dos puntos separan las variables de los par\u00e1metros fijos. Los valores \\(X_i\\) no son conocidos pero son fijos, es decir, que nosotros queremos maximizar el valor del parametro \\(p\\) usando unos valores de \\(X_i\\) que no cambiar\u00e1n durante el proceso (para m\u00e1s informaci\u00f3n mirar esta pregunta de math.stackexchange ). La forma de designar esta funci\u00f3n var\u00eda bastante de un autor a otro. En muchos textos en lugar de la letra \\(L\\) se utiliza \\(\\mathcal{L}\\) para designar a la funci\u00f3n likelihood . Personalmente prefiero reservar \\(\\mathcal{L}\\) para los multiplicadores de Lagrange , pero vamos, que no es algo relevante. Otros simplemente escriben \\(L(p)\\) dando por hecho la existencia de \\(X\\) . Como deber\u00edas de saber para entender lo que viene a continuaci\u00f3n, a la hora de querer maximizar una funci\u00f3n lo m\u00e1s com\u00fan es utilizar la primera derivada e igualarla a 0. Derivar \\(L(p;\\ X)\\) con ese productorio... complicado. Ser\u00eda ideal poder cambiar ese productorio por otra expresi\u00f3n mucho m\u00e1s sencilla de derivar. Eso se consigue de una forma muy r\u00e1pida, aplicando el logaritmo a la funci\u00f3n likelihood . La funci\u00f3n likelihood devuelve una probabilidad, por lo que se encuentra acotada entre 0 y 1. Vamos a recordar la forma de la funci\u00f3n logaritmo . window.addEventListener('load', function() { JXG.Options.text.useMathJax = true; var board = JXG.JSXGraph.initBoard('jxgbox1', { boundingbox: [-1, 2.0, 5.0, -2], showNavigation: false, axis: true, zoom: { factorX: 1.25, factorY: 1.25, wheel: true, needshift: false, eps: 0.1 }, pan: { needshift: false } }); var graph = board.create('functiongraph', [function(x) { return Math.log(x); }]); board.create('text',[3, 1, function() { return '\\\\[\\\\ln\\\\ x\\\\]'; }], { fixed: true, fontSize: 20 }); board.fullUpdate(); }); Se observa que se trata de una funci\u00f3n mon\u00f3tona creciente, es decir, que la curva que representa la funci\u00f3n nunca va para abajo. Para los m\u00e1s curiosos, el \"nunca va para abajo\" se expresa matem\u00e1ticamente con \\(\\forall x \\le y, f(x) \\le f(y)\\) (para m\u00e1s informaci\u00f3n ver funciones mon\u00f3tonas en Wikipedia ). Esto quiere decir que, si aplicamos el logaritmo a la funci\u00f3n \\(L\\) , no cambiar\u00e1 el m\u00e1ximo de la funci\u00f3n. Dicha transformaci\u00f3n nos permitir\u00e1 derivar de forma m\u00e1s sencilla y obtener el mismo m\u00e1ximo que si maximiz\u00e1ramos el productorio original. Es importante darse cuenta de que los valores de la funci\u00f3n cambiar\u00edan (ya no estar\u00edan expresando la probabilidad de \\(X\\) ), pero lo importante es que el m\u00e1ximo es el mismo en las dos funciones. Tras aplicarle el logaritmo, la funci\u00f3n likelihood se suele designar con \\(\\ell\\) y se le llama log-likelihood . Matem\u00e1ticamente se define como \\[\\ell(p;\\ X) = \\ln(L(p;\\ X)) = \\sum_{i = 1}^{N} \\ln P(X_i\\ \\vert\\ p).\\] No solo cambiamos el productorio por un sumatorio, sino que tambi\u00e9n eliminamos el producto que encontr\u00e1bamos al calcular la probabilidad de una sola moneda. \\[ \\begin{align} \\ln P(X_i\\ \\vert\\ p) &= \\ln p^{X_i} + \\ln (1 - p)^{1 - X_i}\\\\ &= X_i \\ln p + (1 - X_i) \\ln (1 - p) \\end{align} \\] En esa \u00faltima l\u00ednea hemos hecho uso de la propiedad que dice \\(\\ln a^b = b \\ln a\\) . La funci\u00f3n completa quedar\u00eda de la siguiente manera: \\[ \\ell(p;\\ X) = \\sum_{i = 1}^{N} \\left[ X_i \\ln p + (1 - X_i) \\ln (1 - p) \\right]. \\] Maximicemos pues la funci\u00f3n \\(\\ell(p;\\ X)\\) igualando a 0 la primera derivada, es decir, \\(\\dfrac{d \\ell(p)}{d p} = 0\\) . \\[ \\require{cancel} \\begin{align} \\dfrac{d \\ell(p;\\ X)}{d p} &= \\sum_{i = 1}^{N} \\left[ \\dfrac{X_i}{p} + \\dfrac{1 - X_i}{1 - p} \\left(\\dfrac{d (1 - p)}{d p}\\right) \\right] = \\\\ &= \\sum_{i = 1}^{N} \\left[ \\dfrac{X_i}{p} + \\dfrac{1 - X_i}{1 - p} (-1) \\right] = \\\\ &= \\sum_{i = 1}^{N} \\left[ \\dfrac{X_i}{p} - \\dfrac{1 - X_i}{1 - p} \\right] = \\\\ &= \\sum_{i = 1}^{N} \\left[ (1 - p) X_i - p (1 - X_i) \\right] =\\\\ &= \\sum_{i = 1}^{N} \\left[ X_i - \\cancel{X_i p} - p + \\cancel{X_i p} \\right] = \\\\ &= \\sum_{i = 1}^{N} \\left[ X_i - p \\right] = \\\\ &= - N p + \\sum_{i = 1}^{N} X_i = 0\\\\ \\end{align} \\] Por si alguien se ha perdido durante la derivaci\u00f3n aclarar\u00e9 las 2 cosas que m\u00e1s problemas pueden dar. \\(\\dfrac{d \\ln f(x)}{d x} = \\dfrac{1}{f(x)} f'(x)\\) , siendo \\(f\\) una funci\u00f3n cualquiera. \\(\\sum_{i = 1}^{N} c = Nc\\) siendo \\(c\\) una constante cualquiera. En la derivaci\u00f3n el par\u00e1metro \\(p\\) no cambia conforme cambiamos de lanzamiento \\(i\\) , por lo que es una constante dentro de ese sumatorio. Llegados a este punto solo queda despejar \\(p\\) y obtenemos que \\[p = \\dfrac{1}{N} \\sum_{i = 1}^{N} X_i\\text{.}\\] \u00bfOs suena este resultado? Seguro que s\u00ed. Vamos a escribirlo utilizando palabras m\u00e1s amigables. \\[p = \\dfrac{\\text{n\u00famero de caras}}{\\text{n\u00famero de lanzamientos}}.\\] Se trata ex\u00e1ctamente de la misma expresi\u00f3n. El sumatorio cuenta el n\u00famero de caras puesto que \\(X_i = 1\\) cuando el lanzamiento \\(i\\) ha salido cara y \\(X_i = 0\\) cuando ha sido cruz. El n\u00famero de lanzamientos es \\(N\\) . Debido a que el valor del par\u00e1metro \\(p\\) es una estimaci\u00f3n y no es su valor real (no sabemos el valor real de la moneda que ha generado dichos lanzamientos) se le suele poner un sombrerito encima \\(\\hat{p}\\) . Por lo tanto finalmente tenemos que \\(\\hat{p} = \\dfrac{1}{N} \\sum_{i = 1}^{N} X_i\\text{,}\\) lo que traducido a palabras significa que el valor de \\(p\\) estimado con el MLE no es otra cosa que el n\u00famero de caras entre el n\u00famero total de lanzamientos.","title":"Funci\u00f3n Likelihood"},{"location":"math/maximum-likelihood-estimation-2/#que-hemos-hecho","text":"A modo de resumen voy a exponer los pasos seguidos para obtener el resultado final. En primer lugar hemos definido \\(X\\) como una serie de lanzamientos de una moneda. Hemos obtenido una expresi\u00f3n que nos permite hallar la probabilidad de un lanzamiento dado, \\(P(X_i\\ \\vert\\ p)\\) . Multiplicando el valor de probabilidad de cada moneda obtenemos la probabilidad conjunta de todos los lanzamientos, \\(P(X\\ \\vert\\ p)\\) . Hemos creado una funci\u00f3n, likelihood function , que devuelve la probabilidad conjunta en funci\u00f3n de \\(p\\) , \\(L(p;\\ X)\\) . Con el objetivo de maximizar esa funci\u00f3n le hemos aplicado el logaritmo obteniendo as\u00ed la funci\u00f3n log-likelihood , \\(\\ell(p;\\ X)\\) . Igualamos la primera derivada de esa funci\u00f3n a \\(0\\) y despejamos \\(p\\) para obtener as\u00ed la estimaci\u00f3n, es decir, \\(\\hat{p}\\) . A modo de pr\u00e1ctica podr\u00edas intentar repetir t\u00fa solo el proceso y comprobar que has llegado al mismo resultado. Deja pasar unos d\u00edas para que se te olvide lo que acabas de leer e int\u00e9ntalo t\u00fa mismo a ver si lo sacas (estoy seguro de que s\u00ed :). Si encuentras cualquier fallo, ya sea hortogr\u00e1fico, algo mal explicado, alg\u00fan n\u00famero que no est\u00e1 donde tiene que estar... lo que sea, d\u00e9jame un comentario. Cualquier duda que tengas tambi\u00e9n es bienvenida al tabl\u00f3n de comentarios. Por cierto, lo de \"hortogr\u00e1fico\" era broma, solo quer\u00eda comprobar si estabas atento \ud83d\ude1c.","title":"\u00bfQu\u00e9 hemos hecho?"},{"location":"math/maximum-likelihood-estimation-2/#creditos","text":"Las im\u00e1genes de las monedas son una modificaci\u00f3n propia de varios ficheros descargados desde Freepik . La gr\u00e1fica del logaritmo ha sido hecha con la ayuda de la librer\u00eda JSXGraph . .coin, .head, .tail { background-size: cover; display: inline-block; height: 2em; width: 2em; vertical-align: middle; margin-top: 1px; } .head { background-image: url(\"/assets/images/2018_10_18_coin_head.png\"); } .tail { background-image: url(\"/assets/images/2018_10_18_coin_tail.png\"); } .MathJax_Display > span.MathJax { overflow-y: hidden; overflow-x: auto; display: block; text-align: center; outline: 0; }","title":"Cr\u00e9ditos"},{"location":"problems/euler-phi-totient-function/","tags":["Math","Codeforces","Euler"],"text":"\ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function Esta semana me top\u00e9 con este problema en una competici\u00f3n de CodeForces. Es bastante obvio que no se puede resolver con fuerza bruta para valores grandes. \u00bfC\u00f3mo se resuelve entonces? Primero analicemos el problema y luego os presentar\u00e9 a la funci\u00f3n matem\u00e1tica aliada que nos ayudar\u00e1 en la batalla contra este enunciado. El enunciado es el siguiente. Tenemos dos n\u00fameros enteros \\(a\\) y \\(m\\) tal que \\(1 \\le a < m \\le 10^{10}\\) y el problema nos pide que contemos cuantos valores puede tomar el entero \\(x\\) tal que \\(0 \\le x < m\\) y se cumpla \\(\\gcd(a, m) = \\gcd(a + x, m)\\) . \\(\\gcd\\) representa el m\u00e1ximo com\u00fan divisor ( greatest common divisor en ingl\u00e9s). Greatest common divisor Lo primero es tener claro el significado de m\u00e1ximo com\u00fan divisor . El m\u00e1ximo com\u00fan divisor de dos n\u00fameros cualesquiera es la intersecci\u00f3n de los factores primos que forman dichos n\u00fameros. Esta imagen de Wikipedia deber\u00eda dejar m\u00e1s clara la definici\u00f3n: M\u00e1ximo com\u00fan divisor explicado gr\u00e1ficamente. La intersecci\u00f3n de los factores primos de 48 y 60 es: 2, 2, y 3. Por lo tanto, el \\(\\gcd(48, 60) = 2 \\cdot 2 \\cdot 3 = 12\\). Dicho de otra forma, 12 es el n\u00famero m\u00e1ximo que puede dividir de manera exacta a 48 y a 60. (Imagen: Wikipedia) El m\u00e1ximo com\u00fan m\u00faltiplo se resuelve eficientemente usando un algoritmo conocido desde tiempos de la antigua Grecia. Se trata del algoritmo de Euclides . Desarrollo del problema Una vez entendidos todos los elementos que aparecen en el enunciado del problema podemos proceder con su resoluci\u00f3n. Definamos \\(y = a + x\\) . \u00bfQu\u00e9 podemos decir de los valores de \\(y\\) que cumplen el requerimiento del enunciado? Sabemos que \\(y \\in [a, a + m)\\) por la propia definici\u00f3n de \\(x\\) dada en el enunciado. \u00bfQu\u00e9 m\u00e1s sabemos? Sabemos que entre los factores primos que componen \\(y\\) deben encontrarse aquellos que componen \\(\\gcd(a, m)\\) , y pueden contener otros factores distintos de aquellos que componen \\(\\frac{m}{\\gcd(a, m)}\\) (es decir, los factores que componen \\(m\\) excepto aquellos que forman parte del \\(\\gcd(a, m)\\) ). Utilicemos los n\u00fameros \\(a=48\\) y \\(m=60\\) del ejemplo de la anterior imagen para aclarar esto \u00faltimo que he dicho. \\(\\gcd(48, 60) = 2 \\cdot 2 \\cdot 3 = 12\\) . \\(y\\) debe tener 2, 2, y 3 entre sus factores pero no el 5. Si no tuviera ni 2, 2 o 3 entre sus factores, o si tuviera el 5, \\(\\gcd(y, 60)\\) ser\u00eda distinto de 12. Dicho de otra forma, \\(y\\) debe de ser un m\u00faltiplo de 12 que no contenga el 5 entre sus factores. Vamos a definir \\(y = 12 \\cdot k\\) , \u00bfcu\u00e1ntos valores de \\(k\\) no contienen el n\u00famero 5 entre sus factores? Dicho de otra forma, \u00bfcu\u00e1ntos n\u00fameros primos relativos a 5 hay? Realmente hay infinitos, pero \u00bfcu\u00e1ntos hay en el rango \\(y \\in [a, a + m) = [48, 48+60) = [48, 108)\\) ? Los valores que puede tomar \\(k\\) son 4, 5, 6, 7 y 8 para que \\(y\\) est\u00e9 en el rango indicado. De todos esos, obviamente el 5 no es primo relativo de 5. Por lo que hay cuatro valores v\u00e1lidos de \\(k\\) . Valores v\u00e1lidos de \\(k\\) \\(\\color{red}k = 3 \\to y = 12 \\cdot 3 = 36 \\notin [48, 108)\\) \\(\\color{green}k = 4 \\to y = 12 \\cdot 4 = 48 \\in [48, 108)\\) \\(\\color{red}k = 5 \\to y = 12 \\cdot 5 = 60 \\in [48, 108)\\) , aunque est\u00e1 en el intervalo no es primo relativo de 5. \\(\\color{green}k = 6 \\to y = 12 \\cdot 6 = 72 \\in [48, 108)\\) \\(\\color{green}k = 7 \\to y = 12 \\cdot 7 = 84 \\in [48, 108)\\) \\(\\color{green}k = 8 \\to y = 12 \\cdot 8 = 96 \\in [48, 108)\\) \\(\\color{red}k = 9 \\to y = 12 \\cdot 9 = 108 \\notin [48, 108)\\) \u00bfC\u00f3mo podemos simplificar ese c\u00e1lculo? Para ello hay que darse cuenta de una cosa. Para todo valor de \\(y > m, \\gcd(y, m) = \\gcd(y - m, m)\\) . Si esto no te convence haz una pausa y conv\u00e9ncete a ti mismo de que esto es as\u00ed. Busca recursos sobre el m\u00e1ximo com\u00fan divisor para entenderlo mejor. Adem\u00e1s, como \\(0 \\le x < m\\) , sabemos que hay \\(m\\) valores distintos de \\(x\\) . Esto b\u00e1sicamente transforma nuestra pregunta a: \u00bfcu\u00e1ntos valores de \\(k\\) menores de 5 son coprimos de 5? Euler Phi function o Euler Totient function La respuesta directa a esta pregunta la da la funci\u00f3n \\(\\varphi(n)\\) de Euler, tambi\u00e9n conocida como la funci\u00f3n indicatriz de Euler ( Totient function en ingl\u00e9s). Esta funci\u00f3n devuelve la cantidad de n\u00fameros menores de \\(n\\) que son primos relativos de \\(n\\) . Justo lo que necesitamos. Puesto que esta funci\u00f3n nos da lo que necesitamos, lo que debemos programar es: \\[ \\varphi\\left(\\dfrac{m}{\\gcd(a, m)}\\right) \\] Vamos a ir desgranando el comportamiento de esta funci\u00f3n. Empezando con una definici\u00f3n formal, que no viene siendo m\u00e1s que la forma matem\u00e1tica de escribir lo comentado en el p\u00e1rrafo anterior. \\[ \\varphi(m)=|\\{n\\in \\mathbb{N} |n\\leq m\\land \\gcd(m,n)=1\\}| \\] \\(\\varphi(m)\\) es el n\u00famero de elementos (denotado por \\(|\\cdot|\\) ) del conjunto ( \\(\\{\\cdot\\}\\) ) formado por los n\u00fameros naturales ( \\(\\mathbb{N}\\) , no incluye el 0) que son menores de \\(m\\) y que son primos relativos o coprimos de \\(m\\) (dicho de otra forma, \\(\\gcd(m, n) = 1\\) ). Empecemos con alg\u00fan ejemplo. Supongamos que queremos obtener todos los n\u00fameros menores de 11 y coprimos a 11. Pues bien, es f\u00e1cil darse cuenta de que 11 es un n\u00famero primo, por lo que hay 10 n\u00fameros naturales menores que 11 que no comparten ning\u00fan factor primo con \u00e9l: \\[ \\varphi(11) = |\\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\}| = 10 \\] Siendo \\(p\\) un n\u00famero primo, la f\u00f3rmula general es: \\[ \\varphi(p) = p - 1 \\] \u00bfQu\u00e9 pasa con \\(\\varphi(8)\\) ? \\[ \\require{cancel} \\varphi(8) = |\\{1, \\xcancel{2}, 3, \\xcancel{4}, 5, \\xcancel{6}, 7\\}| = 4 \\] 8 no es primo, pero puede descomponerse f\u00e1cilmente en \\(2^3\\) . 8 es en realidad la potencia de un primo \\(p = 2\\) . En lugar de pintarlo como una lista vamos a distribuirlo como una matriz con \\(p\\) columnas: \\[ \\require{cancel} \\varphi(2^3) = \\left| \\begin{Bmatrix} 1 & \\xcancel{2} \\\\ 3 & \\xcancel{4} \\\\ 5 & \\xcancel{6} \\\\ 7 & \\xcancel{8} \\end{Bmatrix} \\right| = 4 \\] Se observa que la \u00faltima columna contiene todos los m\u00faltiplos de \\(p\\) , lo cu\u00e1l es bastante obvio porque la \u00faltima columna es la columna \\(p\\) . Para extraer la f\u00f3rmula general de \\(\\varphi(p^n)\\) quiz\u00e1s sea \u00fatil pintar otro ejemplo. Pintemos \\(\\varphi(3^2)\\) : \\[ \\require{cancel} \\varphi(3^2) = \\left| \\begin{Bmatrix} 1 & 2 & \\xcancel{3} \\\\ 4 & 5 & \\xcancel{6} \\\\ 7 & 8 & \\xcancel{9} \\end{Bmatrix} \\right| = 6 \\] Puedes pintar algunos casos m\u00e1s si lo deseas, pero yo paso directamente a mostrarte la expresi\u00f3n general. La forma de calcularlo es tomando el total de n\u00fameros y rest\u00e1ndole la cantidad de n\u00fameros que hay en la \u00faltima columna: \\[ \\varphi(p^n) = p^n - p^{n - 1} = (p - 1) p^{n - 1} \\] \u00bfProblemas para entender la f\u00f3rmula anterior? Sabemos que la matriz que hemos definido tiene \\(p\\) columnas. Tambi\u00e9n sabemos que hay \\(p^n\\) elementos en la matriz. \u00bfCu\u00e1ntos elementos hay en cada columna? Llamemos \\(x\\) al n\u00famero de elementos en cada columna. Podemos decir que \\(p\\) columnas multiplicado por \\(x\\) elementos que hay en cada columna debe darnos el total de elementos, por lo que \\(px = p^n\\) . De ah\u00ed obtenemos que \\(x = p^{n - 1}\\) . Seguimos. \u00bfCu\u00e1nto vale \\(\\varphi(15)\\) ? 15 no es primo ni es la potencia de un primo, as\u00ed que la f\u00f3rmula anteriormente expuesta no sirve. \\(15 = 3 \\cdot 5\\) , por lo que cualquier n\u00famero menor de 15 que est\u00e9 formado por el factor primo 3 o el factor primo 5 no es coprimo de 15 y no debemos de contarlo. \\[ \\require{cancel} \\varphi(15) = |\\{1, 2, \\xcancel{3}, 4, \\xcancel{5}, \\xcancel{6}, 7, 8, \\xcancel{9}, \\xcancel{10}, 11, \\xcancel{12}, 13, 14, \\xcancel{15}\\}| = 8 \\] De nuevo, pintemos en forma de matriz los n\u00fameros: \\[ \\require{cancel} \\varphi(15) = \\left| \\begin{Bmatrix} 1 & 2 & \\xcancel{3} \\\\ 4 & \\xcancel{5} & \\xcancel{6} \\\\ 7 & 8 & \\xcancel{9} \\\\ \\xcancel{10}& 11 & \\xcancel{12}\\\\ 13 & 14 & \\xcancel{15} \\end{Bmatrix} \\right| = 8 \\] Esta vez es m\u00e1s dif\u00edcil de verlo, pero tenemos que \\(\\varphi(15) = \\varphi(3) \\varphi(5) = 2 \\cdot 4 = 8\\) . Si calculamos el resto (operaci\u00f3n m\u00f3dulo) de cada uno de los valores al dividirlos entre 3, todos los n\u00fameros de una columna dan el mismo resto: la primera columna resto 1, la segunda columna resto 2 y la \u00faltima columna resto 0. Si calculamos el resto para el 5 obtenemos que en cada columna los restos son todos distintos unos a otros, es decir, que los restos van de 0 a 4. Por ejemplo, en la primera columna de arriba a abajo los restos son: 1, 4, 2, 0 y 3. Todos los n\u00fameros son distintos, y solo el elemento que da de resto 0 es m\u00faltiplo de 5. Dicho de otra forma, de esas 3 columnas, en una de ellas todos los n\u00fameros son m\u00faltiplos de 3. Las otras dos son n\u00fameros coprimos a 3. De esas dos columnas restantes, solo 4 de los 5 valores son primos relativos de 5, por lo que tenemos \\(2 \\cdot 4 = 8\\) coprimos de 15. Esto se puede probar m\u00e1s rigurosamente pero no lo har\u00e9 en este art\u00edculo. En las referencias podr\u00e1s encontrar otros recursos que profundizan m\u00e1s en el tema. De forma m\u00e1s general, para cualquier n\u00famero \\(n = p_1^{e_1} p_2^{e_2} \\ldots p_t^{e_t}\\) , siendo \\(p_i^{e^i}\\) el \\(i\\) primo que compone \\(n\\) y \\({e^i}\\) el n\u00famero de veces que aparece dicho primo en la descomposici\u00f3n, se puede escribir la siguiente expresi\u00f3n general: \\[ \\displaystyle \\begin{aligned} \\varphi(n)&=\\varphi(p_1^{e_1} p_2^{e_2} \\ldots p_t^{e_t}) \\\\ &=\\varphi(p_1^{e_1}) \\varphi(p_2^{e_2}) \\ldots \\varphi(p_t^{e_t}) \\\\ &=p_1^{e_1-1} (p_1-1) \\cdot p_2^{e_2-1} (p_2-1) \\cdot \\ldots \\cdot p_t^{e_t-1} (p_t-1) \\\\ &=p_1^{e_1} \\left(1-\\frac{1}{p_1}\\right) \\cdot p_2^{e_2} \\left(1-\\frac{1}{p_2}\\right) \\cdot \\ldots \\cdot p_t^{e_t} \\left(1-\\frac{1}{p_t}\\right) \\\\ &=p_1^{e_1} p_2^{e_2} \\ldots p_t^{e_t} \\cdot \\biggl(1-\\frac{1}{p_1}\\biggr) \\biggl(1-\\frac{1}{p_2}\\biggr) \\ldots \\biggl(1-\\frac{1}{p_t}\\biggr) \\\\ &=n \\cdot \\biggl(1-\\frac{1}{p_1}\\biggr) \\biggl(1-\\frac{1}{p_2}\\biggr) \\ldots \\biggl(1-\\frac{1}{p_t}\\biggr) \\\\ &=n \\prod _{i=1}^{t}\\left(1-{\\frac {1}{p_{i}}}\\right) \\end{aligned} \\] Implementaci\u00f3n La implementaci\u00f3n no tiene mayor historia, es implementar una factorizaci\u00f3n y posteriormente una multiplicaci\u00f3n de los primos (ignorando el exponente de dichos primos). La implementaci\u00f3n de \\(\\gcd(a, b)\\) que usamos es la que est\u00e1 incluida en el m\u00f3dulo est\u00e1ndar de Python math . def prime_factors ( n ): \"\"\"Return a list of the prime factors that compose n. \"\"\" # Factorization is defined for natural numbers. assert n > 0 # Base case. if n == 1 : return [ 1 ] f = [] # Check 2 first for saving half iterations in the next for loop. while n % 2 == 0 : f . append ( 2 ) n /= 2 # Check the odd numbers. We use `+ 1` because range does not include last # value. It's equivalent to < instead of the <= that we want here. for i in range ( 3 , int ( n ** 0.5 ) + 1 , 2 ): while n % i == 0 : f . append ( i ) n /= i # Prime number case. if n > 1 : f . append ( int ( n )) return f def eulers_phi_fun ( n ): \"\"\"Euler's Totient function. \"\"\" f = prime_factors ( n ) val = n # Iterate for the unique list of primes. for i in set ( f ): val *= 1 - 1 / i return int ( val ) def solve ( a , m ): \"\"\"Solve problem for the given a and m. \"\"\" gcd = math . gcd ( a , m ) n = m / gcd phi = eulers_phi_fun ( n ) print ( phi ) Referencias Aqu\u00ed te dejo una lista de enlaces que me ayudaron a entender de qu\u00e9 iba eso de la funci\u00f3n \\(\\varphi\\) de Euler. No solo explican qu\u00e9 es, sino que incluyen muy buenos ejemplos y demostraciones para entenderla en profundidad. Altamente recomendados estos dos v\u00eddeos de Michael Penn: YouTube - Number Theory | Euler's Totient Function: Definition and Basic Example YouTube - The Multiplicativity of Euler's Totient Function Otros recursos: Totient function en Wolfram Alpha Totient function en Wikipedia YouTube - Euler's Phi function proof Proof Wiki - Euler Phi Function is Multiplicative","title":"\ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function"},{"location":"problems/euler-phi-totient-function/#euler-phitotient-function","text":"Esta semana me top\u00e9 con este problema en una competici\u00f3n de CodeForces. Es bastante obvio que no se puede resolver con fuerza bruta para valores grandes. \u00bfC\u00f3mo se resuelve entonces? Primero analicemos el problema y luego os presentar\u00e9 a la funci\u00f3n matem\u00e1tica aliada que nos ayudar\u00e1 en la batalla contra este enunciado. El enunciado es el siguiente. Tenemos dos n\u00fameros enteros \\(a\\) y \\(m\\) tal que \\(1 \\le a < m \\le 10^{10}\\) y el problema nos pide que contemos cuantos valores puede tomar el entero \\(x\\) tal que \\(0 \\le x < m\\) y se cumpla \\(\\gcd(a, m) = \\gcd(a + x, m)\\) . \\(\\gcd\\) representa el m\u00e1ximo com\u00fan divisor ( greatest common divisor en ingl\u00e9s).","title":"\ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function"},{"location":"problems/euler-phi-totient-function/#greatest-common-divisor","text":"Lo primero es tener claro el significado de m\u00e1ximo com\u00fan divisor . El m\u00e1ximo com\u00fan divisor de dos n\u00fameros cualesquiera es la intersecci\u00f3n de los factores primos que forman dichos n\u00fameros. Esta imagen de Wikipedia deber\u00eda dejar m\u00e1s clara la definici\u00f3n: M\u00e1ximo com\u00fan divisor explicado gr\u00e1ficamente. La intersecci\u00f3n de los factores primos de 48 y 60 es: 2, 2, y 3. Por lo tanto, el \\(\\gcd(48, 60) = 2 \\cdot 2 \\cdot 3 = 12\\). Dicho de otra forma, 12 es el n\u00famero m\u00e1ximo que puede dividir de manera exacta a 48 y a 60. (Imagen: Wikipedia) El m\u00e1ximo com\u00fan m\u00faltiplo se resuelve eficientemente usando un algoritmo conocido desde tiempos de la antigua Grecia. Se trata del algoritmo de Euclides .","title":"Greatest common divisor"},{"location":"problems/euler-phi-totient-function/#desarrollo-del-problema","text":"Una vez entendidos todos los elementos que aparecen en el enunciado del problema podemos proceder con su resoluci\u00f3n. Definamos \\(y = a + x\\) . \u00bfQu\u00e9 podemos decir de los valores de \\(y\\) que cumplen el requerimiento del enunciado? Sabemos que \\(y \\in [a, a + m)\\) por la propia definici\u00f3n de \\(x\\) dada en el enunciado. \u00bfQu\u00e9 m\u00e1s sabemos? Sabemos que entre los factores primos que componen \\(y\\) deben encontrarse aquellos que componen \\(\\gcd(a, m)\\) , y pueden contener otros factores distintos de aquellos que componen \\(\\frac{m}{\\gcd(a, m)}\\) (es decir, los factores que componen \\(m\\) excepto aquellos que forman parte del \\(\\gcd(a, m)\\) ). Utilicemos los n\u00fameros \\(a=48\\) y \\(m=60\\) del ejemplo de la anterior imagen para aclarar esto \u00faltimo que he dicho. \\(\\gcd(48, 60) = 2 \\cdot 2 \\cdot 3 = 12\\) . \\(y\\) debe tener 2, 2, y 3 entre sus factores pero no el 5. Si no tuviera ni 2, 2 o 3 entre sus factores, o si tuviera el 5, \\(\\gcd(y, 60)\\) ser\u00eda distinto de 12. Dicho de otra forma, \\(y\\) debe de ser un m\u00faltiplo de 12 que no contenga el 5 entre sus factores. Vamos a definir \\(y = 12 \\cdot k\\) , \u00bfcu\u00e1ntos valores de \\(k\\) no contienen el n\u00famero 5 entre sus factores? Dicho de otra forma, \u00bfcu\u00e1ntos n\u00fameros primos relativos a 5 hay? Realmente hay infinitos, pero \u00bfcu\u00e1ntos hay en el rango \\(y \\in [a, a + m) = [48, 48+60) = [48, 108)\\) ? Los valores que puede tomar \\(k\\) son 4, 5, 6, 7 y 8 para que \\(y\\) est\u00e9 en el rango indicado. De todos esos, obviamente el 5 no es primo relativo de 5. Por lo que hay cuatro valores v\u00e1lidos de \\(k\\) . Valores v\u00e1lidos de \\(k\\) \\(\\color{red}k = 3 \\to y = 12 \\cdot 3 = 36 \\notin [48, 108)\\) \\(\\color{green}k = 4 \\to y = 12 \\cdot 4 = 48 \\in [48, 108)\\) \\(\\color{red}k = 5 \\to y = 12 \\cdot 5 = 60 \\in [48, 108)\\) , aunque est\u00e1 en el intervalo no es primo relativo de 5. \\(\\color{green}k = 6 \\to y = 12 \\cdot 6 = 72 \\in [48, 108)\\) \\(\\color{green}k = 7 \\to y = 12 \\cdot 7 = 84 \\in [48, 108)\\) \\(\\color{green}k = 8 \\to y = 12 \\cdot 8 = 96 \\in [48, 108)\\) \\(\\color{red}k = 9 \\to y = 12 \\cdot 9 = 108 \\notin [48, 108)\\) \u00bfC\u00f3mo podemos simplificar ese c\u00e1lculo? Para ello hay que darse cuenta de una cosa. Para todo valor de \\(y > m, \\gcd(y, m) = \\gcd(y - m, m)\\) . Si esto no te convence haz una pausa y conv\u00e9ncete a ti mismo de que esto es as\u00ed. Busca recursos sobre el m\u00e1ximo com\u00fan divisor para entenderlo mejor. Adem\u00e1s, como \\(0 \\le x < m\\) , sabemos que hay \\(m\\) valores distintos de \\(x\\) . Esto b\u00e1sicamente transforma nuestra pregunta a: \u00bfcu\u00e1ntos valores de \\(k\\) menores de 5 son coprimos de 5?","title":"Desarrollo del problema"},{"location":"problems/euler-phi-totient-function/#euler-phi-function-o-euler-totient-function","text":"La respuesta directa a esta pregunta la da la funci\u00f3n \\(\\varphi(n)\\) de Euler, tambi\u00e9n conocida como la funci\u00f3n indicatriz de Euler ( Totient function en ingl\u00e9s). Esta funci\u00f3n devuelve la cantidad de n\u00fameros menores de \\(n\\) que son primos relativos de \\(n\\) . Justo lo que necesitamos. Puesto que esta funci\u00f3n nos da lo que necesitamos, lo que debemos programar es: \\[ \\varphi\\left(\\dfrac{m}{\\gcd(a, m)}\\right) \\] Vamos a ir desgranando el comportamiento de esta funci\u00f3n. Empezando con una definici\u00f3n formal, que no viene siendo m\u00e1s que la forma matem\u00e1tica de escribir lo comentado en el p\u00e1rrafo anterior. \\[ \\varphi(m)=|\\{n\\in \\mathbb{N} |n\\leq m\\land \\gcd(m,n)=1\\}| \\] \\(\\varphi(m)\\) es el n\u00famero de elementos (denotado por \\(|\\cdot|\\) ) del conjunto ( \\(\\{\\cdot\\}\\) ) formado por los n\u00fameros naturales ( \\(\\mathbb{N}\\) , no incluye el 0) que son menores de \\(m\\) y que son primos relativos o coprimos de \\(m\\) (dicho de otra forma, \\(\\gcd(m, n) = 1\\) ). Empecemos con alg\u00fan ejemplo. Supongamos que queremos obtener todos los n\u00fameros menores de 11 y coprimos a 11. Pues bien, es f\u00e1cil darse cuenta de que 11 es un n\u00famero primo, por lo que hay 10 n\u00fameros naturales menores que 11 que no comparten ning\u00fan factor primo con \u00e9l: \\[ \\varphi(11) = |\\{1, 2, 3, 4, 5, 6, 7, 8, 9, 10\\}| = 10 \\] Siendo \\(p\\) un n\u00famero primo, la f\u00f3rmula general es: \\[ \\varphi(p) = p - 1 \\] \u00bfQu\u00e9 pasa con \\(\\varphi(8)\\) ? \\[ \\require{cancel} \\varphi(8) = |\\{1, \\xcancel{2}, 3, \\xcancel{4}, 5, \\xcancel{6}, 7\\}| = 4 \\] 8 no es primo, pero puede descomponerse f\u00e1cilmente en \\(2^3\\) . 8 es en realidad la potencia de un primo \\(p = 2\\) . En lugar de pintarlo como una lista vamos a distribuirlo como una matriz con \\(p\\) columnas: \\[ \\require{cancel} \\varphi(2^3) = \\left| \\begin{Bmatrix} 1 & \\xcancel{2} \\\\ 3 & \\xcancel{4} \\\\ 5 & \\xcancel{6} \\\\ 7 & \\xcancel{8} \\end{Bmatrix} \\right| = 4 \\] Se observa que la \u00faltima columna contiene todos los m\u00faltiplos de \\(p\\) , lo cu\u00e1l es bastante obvio porque la \u00faltima columna es la columna \\(p\\) . Para extraer la f\u00f3rmula general de \\(\\varphi(p^n)\\) quiz\u00e1s sea \u00fatil pintar otro ejemplo. Pintemos \\(\\varphi(3^2)\\) : \\[ \\require{cancel} \\varphi(3^2) = \\left| \\begin{Bmatrix} 1 & 2 & \\xcancel{3} \\\\ 4 & 5 & \\xcancel{6} \\\\ 7 & 8 & \\xcancel{9} \\end{Bmatrix} \\right| = 6 \\] Puedes pintar algunos casos m\u00e1s si lo deseas, pero yo paso directamente a mostrarte la expresi\u00f3n general. La forma de calcularlo es tomando el total de n\u00fameros y rest\u00e1ndole la cantidad de n\u00fameros que hay en la \u00faltima columna: \\[ \\varphi(p^n) = p^n - p^{n - 1} = (p - 1) p^{n - 1} \\] \u00bfProblemas para entender la f\u00f3rmula anterior? Sabemos que la matriz que hemos definido tiene \\(p\\) columnas. Tambi\u00e9n sabemos que hay \\(p^n\\) elementos en la matriz. \u00bfCu\u00e1ntos elementos hay en cada columna? Llamemos \\(x\\) al n\u00famero de elementos en cada columna. Podemos decir que \\(p\\) columnas multiplicado por \\(x\\) elementos que hay en cada columna debe darnos el total de elementos, por lo que \\(px = p^n\\) . De ah\u00ed obtenemos que \\(x = p^{n - 1}\\) . Seguimos. \u00bfCu\u00e1nto vale \\(\\varphi(15)\\) ? 15 no es primo ni es la potencia de un primo, as\u00ed que la f\u00f3rmula anteriormente expuesta no sirve. \\(15 = 3 \\cdot 5\\) , por lo que cualquier n\u00famero menor de 15 que est\u00e9 formado por el factor primo 3 o el factor primo 5 no es coprimo de 15 y no debemos de contarlo. \\[ \\require{cancel} \\varphi(15) = |\\{1, 2, \\xcancel{3}, 4, \\xcancel{5}, \\xcancel{6}, 7, 8, \\xcancel{9}, \\xcancel{10}, 11, \\xcancel{12}, 13, 14, \\xcancel{15}\\}| = 8 \\] De nuevo, pintemos en forma de matriz los n\u00fameros: \\[ \\require{cancel} \\varphi(15) = \\left| \\begin{Bmatrix} 1 & 2 & \\xcancel{3} \\\\ 4 & \\xcancel{5} & \\xcancel{6} \\\\ 7 & 8 & \\xcancel{9} \\\\ \\xcancel{10}& 11 & \\xcancel{12}\\\\ 13 & 14 & \\xcancel{15} \\end{Bmatrix} \\right| = 8 \\] Esta vez es m\u00e1s dif\u00edcil de verlo, pero tenemos que \\(\\varphi(15) = \\varphi(3) \\varphi(5) = 2 \\cdot 4 = 8\\) . Si calculamos el resto (operaci\u00f3n m\u00f3dulo) de cada uno de los valores al dividirlos entre 3, todos los n\u00fameros de una columna dan el mismo resto: la primera columna resto 1, la segunda columna resto 2 y la \u00faltima columna resto 0. Si calculamos el resto para el 5 obtenemos que en cada columna los restos son todos distintos unos a otros, es decir, que los restos van de 0 a 4. Por ejemplo, en la primera columna de arriba a abajo los restos son: 1, 4, 2, 0 y 3. Todos los n\u00fameros son distintos, y solo el elemento que da de resto 0 es m\u00faltiplo de 5. Dicho de otra forma, de esas 3 columnas, en una de ellas todos los n\u00fameros son m\u00faltiplos de 3. Las otras dos son n\u00fameros coprimos a 3. De esas dos columnas restantes, solo 4 de los 5 valores son primos relativos de 5, por lo que tenemos \\(2 \\cdot 4 = 8\\) coprimos de 15. Esto se puede probar m\u00e1s rigurosamente pero no lo har\u00e9 en este art\u00edculo. En las referencias podr\u00e1s encontrar otros recursos que profundizan m\u00e1s en el tema. De forma m\u00e1s general, para cualquier n\u00famero \\(n = p_1^{e_1} p_2^{e_2} \\ldots p_t^{e_t}\\) , siendo \\(p_i^{e^i}\\) el \\(i\\) primo que compone \\(n\\) y \\({e^i}\\) el n\u00famero de veces que aparece dicho primo en la descomposici\u00f3n, se puede escribir la siguiente expresi\u00f3n general: \\[ \\displaystyle \\begin{aligned} \\varphi(n)&=\\varphi(p_1^{e_1} p_2^{e_2} \\ldots p_t^{e_t}) \\\\ &=\\varphi(p_1^{e_1}) \\varphi(p_2^{e_2}) \\ldots \\varphi(p_t^{e_t}) \\\\ &=p_1^{e_1-1} (p_1-1) \\cdot p_2^{e_2-1} (p_2-1) \\cdot \\ldots \\cdot p_t^{e_t-1} (p_t-1) \\\\ &=p_1^{e_1} \\left(1-\\frac{1}{p_1}\\right) \\cdot p_2^{e_2} \\left(1-\\frac{1}{p_2}\\right) \\cdot \\ldots \\cdot p_t^{e_t} \\left(1-\\frac{1}{p_t}\\right) \\\\ &=p_1^{e_1} p_2^{e_2} \\ldots p_t^{e_t} \\cdot \\biggl(1-\\frac{1}{p_1}\\biggr) \\biggl(1-\\frac{1}{p_2}\\biggr) \\ldots \\biggl(1-\\frac{1}{p_t}\\biggr) \\\\ &=n \\cdot \\biggl(1-\\frac{1}{p_1}\\biggr) \\biggl(1-\\frac{1}{p_2}\\biggr) \\ldots \\biggl(1-\\frac{1}{p_t}\\biggr) \\\\ &=n \\prod _{i=1}^{t}\\left(1-{\\frac {1}{p_{i}}}\\right) \\end{aligned} \\]","title":"Euler Phi function o Euler Totient function"},{"location":"problems/euler-phi-totient-function/#implementacion","text":"La implementaci\u00f3n no tiene mayor historia, es implementar una factorizaci\u00f3n y posteriormente una multiplicaci\u00f3n de los primos (ignorando el exponente de dichos primos). La implementaci\u00f3n de \\(\\gcd(a, b)\\) que usamos es la que est\u00e1 incluida en el m\u00f3dulo est\u00e1ndar de Python math . def prime_factors ( n ): \"\"\"Return a list of the prime factors that compose n. \"\"\" # Factorization is defined for natural numbers. assert n > 0 # Base case. if n == 1 : return [ 1 ] f = [] # Check 2 first for saving half iterations in the next for loop. while n % 2 == 0 : f . append ( 2 ) n /= 2 # Check the odd numbers. We use `+ 1` because range does not include last # value. It's equivalent to < instead of the <= that we want here. for i in range ( 3 , int ( n ** 0.5 ) + 1 , 2 ): while n % i == 0 : f . append ( i ) n /= i # Prime number case. if n > 1 : f . append ( int ( n )) return f def eulers_phi_fun ( n ): \"\"\"Euler's Totient function. \"\"\" f = prime_factors ( n ) val = n # Iterate for the unique list of primes. for i in set ( f ): val *= 1 - 1 / i return int ( val ) def solve ( a , m ): \"\"\"Solve problem for the given a and m. \"\"\" gcd = math . gcd ( a , m ) n = m / gcd phi = eulers_phi_fun ( n ) print ( phi )","title":"Implementaci\u00f3n"},{"location":"problems/euler-phi-totient-function/#referencias","text":"Aqu\u00ed te dejo una lista de enlaces que me ayudaron a entender de qu\u00e9 iba eso de la funci\u00f3n \\(\\varphi\\) de Euler. No solo explican qu\u00e9 es, sino que incluyen muy buenos ejemplos y demostraciones para entenderla en profundidad. Altamente recomendados estos dos v\u00eddeos de Michael Penn: YouTube - Number Theory | Euler's Totient Function: Definition and Basic Example YouTube - The Multiplicativity of Euler's Totient Function Otros recursos: Totient function en Wolfram Alpha Totient function en Wikipedia YouTube - Euler's Phi function proof Proof Wiki - Euler Phi Function is Multiplicative","title":"Referencias"},{"location":"problems/reservoir-sampling/","tags":["Algorithms","Random"],"text":"\ud83c\uddea\ud83c\uddf8 Reservoir sampling Cuando se trata de elegir un elemento aleatorio con igual probabilidad de entre los elementos de un array lo primero que hacemos es buscar el \"m\u00e9todo random int\" en el lenguaje de programaci\u00f3n en cuesti\u00f3n y generar un entero entre 0 y el n\u00famero de elementos - 1 (suponiendo que el primer \u00edndice del array es 0). Utilizamos ese n\u00famero como \u00edndice y devolvemos el elemento que se encuentra en esa posici\u00f3n. El generador de enteros aleatorios debe seguir una distribuci\u00f3n uniforme, es decir, todos los n\u00fameros enteros en el rango indicado tienen la misma posibilidad de ser elegidos. Un ejemplo de c\u00f3digo en Python que selecciona un n\u00famero aleatorio de una lista ser\u00eda: import random my_list = [ 1 , 2 , 3 , 4 ] idx = random . randint ( 0 , len ( my_list ) - 1 ) my_list [ idx ] # Un elemento cualquiera de la lista. En funci\u00f3n del lenguaje de programaci\u00f3n seleccionado la sintaxis puede variar, pero la l\u00f3gica es la misma. Algo digno de menci\u00f3n de esta implementaci\u00f3n de randint es que el segundo par\u00e1metro (el n\u00famero m\u00e1ximo a generar) est\u00e1 incluido entre los n\u00fameros generados, por lo que tenemos que restarle 1. Nota: en Python podr\u00edamos usar directamente random.choice(my_list) para obtener un elemento aleatorio sin tener que generar el \u00edndice nosotros, pero es generado internamente. \u00bf C\u00f3mo har\u00edamos eso mismo sobre una lista de la que no sabemos el n\u00famero total de elementos ? Es posible que la lista sea tan grande que no quepa en memoria, o simplemente, en lugar de una lista, tenemos un stream continuo de datos y queremos devolver (cuando el stream finalize) un elemento siguiendo una distribuci\u00f3n uniforme. Vamos a soluciona este problema paso a paso. Continuar\u00e9 usando Python para mostrar un ejemplo de implementaci\u00f3n. Como siempre, en primer lugar los imports . Usar\u00e9 NumPy por costumbre, pero se podr\u00eda hacer perfectamente usando listas normales de Python, como se mostr\u00f3 en el primer ejemplo. % matplotlib inline import matplotlib.pyplot as plt import numpy as np # N\u00famero de elementos de la lista generada. N_ELEMENTS = 10 # Semilla aleatoria para reproducir experimentos. SEED = 124 np . random . seed ( SEED ) Despu\u00e9s de los imports y de fijar una semilla aleatoria para poder reproducir experimentos, generaremos una lista aleatoria. La lista contine n\u00fameros enteros en el rango [-n_elements, -1] . Decid\u00ed poner los n\u00fameros negativos para diferenciar entre los \u00edndices del array y los valores del array. El desordenar los n\u00fameros es para darle un aspecto m\u00e1s ca\u00f3tico :) def get_random_list ( n_elements ): # Generamos lista ordenada desde -n_elements hasta -1. random_list = np . arange ( 0 , n_elements ) - n_elements # Desordenamos la lista. random_list = np . random . permutation ( random_list ) return random_list random_list = get_random_list ( N_ELEMENTS ) random_list Si utilizas la misma semilla aleatoria que yo, la lista aleatoria random_list debe contener: array([ -4, -2, -7, -5, -6, -10, -1, -8, -3, -9]) . Aunque se trate de un array de NumPy, el objeto random_list se puede utilizar en la mayor\u00eda de los casos como una lista de Python. Por ejemplo, podemos ejecutar la siguiente l\u00ednea para obtener el tama\u00f1o del array: len ( random_list ) # 10 Sin embargo, si convertimos la lista en un iterador no podr\u00edamos hacer eso. Ejecutar len(iter(random_list)) dar\u00eda error. Utilizaremos iteradores para simular ese stream de longitud indeterminada del que hablamos antes. Una soluci\u00f3n honrada a este problema ser\u00eda pensar de la siguiente forma: Muy bien, no tenemos la longitud de la lista pero podemos recorrer el iterador hasta que nos quedemos sin elementos. De esta forma sabr\u00edamos el n\u00famero total de elementos con los que contamos y podr\u00edamos utilizar el m\u00e9todo \"cl\u00e1sico\" que ya conocemos que nos permite seleccionar elementos random de una lista siguiendo una distribuci\u00f3n uniforme. Pues s\u00ed, podr\u00eda hacerse eso. \u00bfEl problema? Que necesitar\u00edamos ir guardando todos los elementos que vamos iterando para poder elegir uno. Esto viola una de las condiciones iniciales del enunciado del problema: no queremos mantener toda la lista en memoria. De todas formas, vamos a implementar este m\u00e9todo para comprobar que funciona. def sample_list ( random_iter ): # Convertimos el iterador en una lista. random_list = [ i for i in random_iter ] # Obtenemos un elemento aleatorio como hicimos anteriormente. length = len ( random_list ) idx = np . random . randint ( 0 , length - 1 ) return random_list [ idx ] sample_list ( iter ( random_list )) Esto parece funcionar y devuelve un elemento aleatorio de la lista. Con mi semilla aleatoria el resultado es -10 . De todas formas vamos a repetir este proceso muchas veces y pintar en un histograma la frecuencia con la que se elige cada elemento. def test_sample_method ( method , random_list , n_times ): samples = [] for i in range ( n_times ): samples . append ( method ( iter ( random_list ))) plt . hist ( samples ) test_sample_method ( sample_list , random_list , 40 ) El resultado es bastante interesante. \u00bfCasualmente no se ha elegido el n\u00famero -9 o hay un fallo en nuestra funci\u00f3n? Ejecutemos unos cuantos experimentos m\u00e1s para asegurarnos que no ha sido casualidad. En lugar de 40 ejecutemos 10000. test_sample_method ( sample_list , random_list , 10000 ) Parece que tenemos un fallo en nuestro selector de samples. \u00bfLo ves? Al contrario de lo que hac\u00edamos en el primer ejemplo de c\u00f3digo con el que se iniciaba el post, aqu\u00ed no estamos generando el n\u00famero aleatorio usando Python, sino que estamos usando la funci\u00f3n de NumPy np.random.randint . Esta funci\u00f3n no incluye el \u00faltimo elemento entre los devueltos, por lo que no es necesario restarle 1 al segundo par\u00e1metro. El elemento -9 nunca era devuelto puesto que es el \u00faltimo de la lista. Corregimos el error y volvemos a pintar el histograma. def sample_list ( random_iter ): random_list = [ i for i in random_iter ] length = len ( random_list ) # Ya no ponemos lenght - 1!! idx = np . random . randint ( 0 , length ) return random_list [ idx ] test_sample_method ( sample_list , random_list , 10000 ) Ahora s\u00ed observamos que cada unon de los n\u00fameros ha sido elegido un n\u00famero similar de veces. Pues bien, ya tenemos el framework montado para escribir una funci\u00f3n distinta a sample_list que resuelva el problema de una forma m\u00e1s eficiente (sin tener que mantener en memoria toda la lista). \u00bfAlguna otra idea de c\u00f3mo resolverlo? Podr\u00edamos leer primero el stream para averiguar el n\u00famero de elementos, generar un n\u00famero aleatorio en el rango de la lista y, posteriormente, volver a leer el stream desde el principio y seleccionar el elemento que se corresponde con el \u00edndice seleccionado. Esta otra opci\u00f3n tiene un punto d\u00e9bil muy claro: debemos de leer el stream 2 veces. Directamente nos saltaremos esta implementaci\u00f3n e iremos con la forma m\u00e1s eficiente: un algoritmo que nos permite hacer esa selecci\u00f3n leyendo una \u00fanica vez el stream y sin almacenar toda la lista en memoria. Reservoir sampling Todo lo anterior comentado no es m\u00e1s que una introducci\u00f3n larga para llegar a la descripci\u00f3n del algoritmo reservoir sampling . El funcionamiento de este algoritmo se basa en seleccionar aleatoriamente elementos provisionales hasta que termina el stream. Cuando finaliza el stream, el \u00faltimo elemento provisional seleccionado es devuelto, de forma que la probablidad de seleccionar un elemento del stream es ex\u00e1ctamente la misma para todos los elementos. Guardando \u00fanicamente un solo elemento en memoria la complejidad espacial de este algoritmo es \\( \\(\\mathcal{O}(1)\\) \\) y, puesto que solo se leen los elementos una vez, la complejidad temporal es \\( \\(\\mathcal{O}(n)\\) \\) siendo \\(n\\) el n\u00famero de elementos del stream. Formalizemos el problema usando matem\u00e1ticas. Queremos que la probabilidad de elegir un elemento \\( \\(x_i\\) \\) de la lista \\( \\(\\mathbf{x} = {x_1, x_2, \\cdots, x_n}\\) \\) sea \\( \\(P(x_i) = \\dfrac{1}{n}\\) \\) para todo valor de \\( \\(1 \\leq i \\leq n\\) \\) . Sup\u00f3n que comienza el stream y recibes un elemento. Si dejamos pasar ese elemento y el stream finaliza sin darte ning\u00fan elemento m\u00e1s, tendr\u00edamos un problema puesto que nuestro algoritmo no devolver\u00eda ning\u00fan elemento aleatorio de la lista. El primer elemento hay que cogerlo s\u00ed o s\u00ed. Con cogerlo me refiero a guardarlo temporalmente en memoria. Si el stream termina ah\u00ed, tendr\u00edamos que devolver ese elemento sin m\u00e1s. Esto tiene sentido puesto que cuando tenemos un solo elemento en la lista la probabilidad de cogerlo es 1: $$ P_1(x_1) = \\dfrac{1}{n} = \\dfrac{1}{1} = 1 $$. Con \\( \\(P_1\\) \\) indico que hemos le\u00eddo un solo elemento del stream. Si el stream no termina, hay que seguir leyendo elementos y sustituir aleatoriamente el antiguo elemento por uno de los nuevos. Cuando leemos un segundo elemento deber\u00edamos tener: $$ P_2(x_2) = \\dfrac{1}{n} = \\dfrac{1}{2} = 0.5 $$. Es decir, la mitad de las veces sustituir\u00edamos el elemento provisional (el primer elemento) por el segundo. Para realizar esto en Python podemos evaluar la condici\u00f3n np.random.randint(0, 2) == 0 . La funci\u00f3n randint nos devolver\u00e1 o un 0 o un 1 de manera uniforme, por lo que la mitad de las veces ser\u00e1 0. Si se cumple la condici\u00f3n, podremos sustituir el elemento provisional por el nuevo. \\( \\(P_2(x_2) = 0.5\\) \\) , tal y como deber\u00eda de ser. Pero ahora que hemos a\u00f1adido un elemento nuevo \u00bfcu\u00e1l es la probabilidad de acabar eligiendo el primer elemento? Es decir, \u00bfcu\u00e1nto vale \\( \\(P_2(x_1)\\) \\) ? \u00bfSigue siendo \\( \\(P_2(x_1) = P_1(x_1) = 1\\) \\) ? Ovbiamente ya no es 1 puesto que la mitad de las veces ser\u00e1 sustituido por el segundo elemento. La nueva probabilidad de elegir el primer elemento es la probabilidad de elegir el elemento en el paso anterior ( \\( \\(P_1(x_1)\\) \\) ) por la probabilidad de no elegir el segundo elemento ( \\( \\(1 - P_2(x_2)\\) \\) ). Traduciendo a una expresi\u00f3n matem\u00e1tica tenemos que: $$ P_2(x_1) = P_1(x_1) \\cdot (1 - P_2(x_2)) = 1 \\cdot (1 - 0.5) = 0.5 $$. La posible sustituci\u00f3n de \\( \\(x_1\\) \\) cuando se lee el segundo elemento cambia la probabilidad de elegir \\( \\(x_1\\) \\) , y dicha probabilidad coincide con una distribuci\u00f3n uniforme. Podr\u00eda seguir derivando para un tercer elemento, pero directamente voy a escribir la expresi\u00f3n general. \\[ \\begin{aligned} P_n(x_n) &= \\dfrac{1}{n} \\\\ P_n(x_i) &= P_{n-1}(x_i) \\cdot (1 - P_{i+1}(x_{i+1})) \\cdot (1 - P_{i+2}(x_{i+2})) \\cdots (1 - P_n(x_n)) \\end{aligned} \\] para todo valor de \\( \\(i < n\\) \\) . Ahora, partiendo de la expresi\u00f3n general obtengamos la expresi\u00f3n para 3 elementos. \\[ \\begin{aligned} P_3(x_3) &= \\dfrac{1}{3} \\\\ P_3(x_2) &= P_2(x_2) \\cdot (1 - P_3(x_3)) = \\dfrac{1}{2} \\cdot \\left( 1 - \\dfrac{1}{3} \\right) = \\dfrac{1}{2} \\cdot \\dfrac{2}{3} = \\dfrac{2}{6} = \\dfrac{1}{3} \\\\ P_3(x_1) &= P_2(x_1) \\cdot (1 - P_2(x_2)) \\cdot (1 - P_3(x_3)) = \\\\ &= \\dfrac{1}{2} \\cdot \\left(1 - \\dfrac{1}{2}\\right) \\cdot \\left(1 - \\dfrac{1}{3}\\right) = \\dfrac{1}{2} \\cdot \\dfrac{1}{2} \\cdot \\dfrac{2}{3} = \\dfrac{2}{6} = \\dfrac{1}{3} \\end{aligned} \\] Como se observa, \\( \\(P_3(x_1) = P_3(x_2) = P_3(x_3) = \\dfrac{1}{3}\\) \\) , por lo que cumple con los requisitos. Implementaci\u00f3n La implementaci\u00f3n es muy sencilla, la puedes encontrar justo debajo. def sample_reservoir ( random_iter ): # Cogemos el primer elemento como elemento provisional. sample = next ( random_iter ) for i , n in enumerate ( random_iter ): # Cambiamos el sample cada vez que leemos un nuevo elemento con # probabilidad 1 / n_elementos_leidos. if np . random . randint ( 0 , i + 1 ) == 0 : sample = n # Devolvemos el \u00faltimo sample seleccionado. return sample sample_reservoir ( iter ( random_list )) Con mi semilla aleatoria me proporciona un -5 . Pintemos el histograma despu\u00e9s de haber seleccionado 10000 elementos. test_sample_method ( sample_list , random_list , 10000 ) Efectivamente, con esta nueva funci\u00f3n tambi\u00e9n obtenemos un histograma propio de una distribuci\u00f3n uniforme. \u00a1Misi\u00f3n cumplida! Puedes encontrar un notebook de Python con el c\u00f3digo en el repositorio. Recuerda que para obtener exactamente los mismos resultados debes de ejecutar el notebook de principio a fin, puesto que la semilla aleatoria se configura al principio. Si ejecutas una celda dos veces har\u00e1 que el resultado de las siguientes no sea exactamente el mismo que el m\u00edo.","title":"\ud83c\uddea\ud83c\uddf8 Reservoir sampling"},{"location":"problems/reservoir-sampling/#reservoir-sampling","text":"Cuando se trata de elegir un elemento aleatorio con igual probabilidad de entre los elementos de un array lo primero que hacemos es buscar el \"m\u00e9todo random int\" en el lenguaje de programaci\u00f3n en cuesti\u00f3n y generar un entero entre 0 y el n\u00famero de elementos - 1 (suponiendo que el primer \u00edndice del array es 0). Utilizamos ese n\u00famero como \u00edndice y devolvemos el elemento que se encuentra en esa posici\u00f3n. El generador de enteros aleatorios debe seguir una distribuci\u00f3n uniforme, es decir, todos los n\u00fameros enteros en el rango indicado tienen la misma posibilidad de ser elegidos. Un ejemplo de c\u00f3digo en Python que selecciona un n\u00famero aleatorio de una lista ser\u00eda: import random my_list = [ 1 , 2 , 3 , 4 ] idx = random . randint ( 0 , len ( my_list ) - 1 ) my_list [ idx ] # Un elemento cualquiera de la lista. En funci\u00f3n del lenguaje de programaci\u00f3n seleccionado la sintaxis puede variar, pero la l\u00f3gica es la misma. Algo digno de menci\u00f3n de esta implementaci\u00f3n de randint es que el segundo par\u00e1metro (el n\u00famero m\u00e1ximo a generar) est\u00e1 incluido entre los n\u00fameros generados, por lo que tenemos que restarle 1. Nota: en Python podr\u00edamos usar directamente random.choice(my_list) para obtener un elemento aleatorio sin tener que generar el \u00edndice nosotros, pero es generado internamente. \u00bf C\u00f3mo har\u00edamos eso mismo sobre una lista de la que no sabemos el n\u00famero total de elementos ? Es posible que la lista sea tan grande que no quepa en memoria, o simplemente, en lugar de una lista, tenemos un stream continuo de datos y queremos devolver (cuando el stream finalize) un elemento siguiendo una distribuci\u00f3n uniforme. Vamos a soluciona este problema paso a paso. Continuar\u00e9 usando Python para mostrar un ejemplo de implementaci\u00f3n. Como siempre, en primer lugar los imports . Usar\u00e9 NumPy por costumbre, pero se podr\u00eda hacer perfectamente usando listas normales de Python, como se mostr\u00f3 en el primer ejemplo. % matplotlib inline import matplotlib.pyplot as plt import numpy as np # N\u00famero de elementos de la lista generada. N_ELEMENTS = 10 # Semilla aleatoria para reproducir experimentos. SEED = 124 np . random . seed ( SEED ) Despu\u00e9s de los imports y de fijar una semilla aleatoria para poder reproducir experimentos, generaremos una lista aleatoria. La lista contine n\u00fameros enteros en el rango [-n_elements, -1] . Decid\u00ed poner los n\u00fameros negativos para diferenciar entre los \u00edndices del array y los valores del array. El desordenar los n\u00fameros es para darle un aspecto m\u00e1s ca\u00f3tico :) def get_random_list ( n_elements ): # Generamos lista ordenada desde -n_elements hasta -1. random_list = np . arange ( 0 , n_elements ) - n_elements # Desordenamos la lista. random_list = np . random . permutation ( random_list ) return random_list random_list = get_random_list ( N_ELEMENTS ) random_list Si utilizas la misma semilla aleatoria que yo, la lista aleatoria random_list debe contener: array([ -4, -2, -7, -5, -6, -10, -1, -8, -3, -9]) . Aunque se trate de un array de NumPy, el objeto random_list se puede utilizar en la mayor\u00eda de los casos como una lista de Python. Por ejemplo, podemos ejecutar la siguiente l\u00ednea para obtener el tama\u00f1o del array: len ( random_list ) # 10 Sin embargo, si convertimos la lista en un iterador no podr\u00edamos hacer eso. Ejecutar len(iter(random_list)) dar\u00eda error. Utilizaremos iteradores para simular ese stream de longitud indeterminada del que hablamos antes. Una soluci\u00f3n honrada a este problema ser\u00eda pensar de la siguiente forma: Muy bien, no tenemos la longitud de la lista pero podemos recorrer el iterador hasta que nos quedemos sin elementos. De esta forma sabr\u00edamos el n\u00famero total de elementos con los que contamos y podr\u00edamos utilizar el m\u00e9todo \"cl\u00e1sico\" que ya conocemos que nos permite seleccionar elementos random de una lista siguiendo una distribuci\u00f3n uniforme. Pues s\u00ed, podr\u00eda hacerse eso. \u00bfEl problema? Que necesitar\u00edamos ir guardando todos los elementos que vamos iterando para poder elegir uno. Esto viola una de las condiciones iniciales del enunciado del problema: no queremos mantener toda la lista en memoria. De todas formas, vamos a implementar este m\u00e9todo para comprobar que funciona. def sample_list ( random_iter ): # Convertimos el iterador en una lista. random_list = [ i for i in random_iter ] # Obtenemos un elemento aleatorio como hicimos anteriormente. length = len ( random_list ) idx = np . random . randint ( 0 , length - 1 ) return random_list [ idx ] sample_list ( iter ( random_list )) Esto parece funcionar y devuelve un elemento aleatorio de la lista. Con mi semilla aleatoria el resultado es -10 . De todas formas vamos a repetir este proceso muchas veces y pintar en un histograma la frecuencia con la que se elige cada elemento. def test_sample_method ( method , random_list , n_times ): samples = [] for i in range ( n_times ): samples . append ( method ( iter ( random_list ))) plt . hist ( samples ) test_sample_method ( sample_list , random_list , 40 ) El resultado es bastante interesante. \u00bfCasualmente no se ha elegido el n\u00famero -9 o hay un fallo en nuestra funci\u00f3n? Ejecutemos unos cuantos experimentos m\u00e1s para asegurarnos que no ha sido casualidad. En lugar de 40 ejecutemos 10000. test_sample_method ( sample_list , random_list , 10000 ) Parece que tenemos un fallo en nuestro selector de samples. \u00bfLo ves? Al contrario de lo que hac\u00edamos en el primer ejemplo de c\u00f3digo con el que se iniciaba el post, aqu\u00ed no estamos generando el n\u00famero aleatorio usando Python, sino que estamos usando la funci\u00f3n de NumPy np.random.randint . Esta funci\u00f3n no incluye el \u00faltimo elemento entre los devueltos, por lo que no es necesario restarle 1 al segundo par\u00e1metro. El elemento -9 nunca era devuelto puesto que es el \u00faltimo de la lista. Corregimos el error y volvemos a pintar el histograma. def sample_list ( random_iter ): random_list = [ i for i in random_iter ] length = len ( random_list ) # Ya no ponemos lenght - 1!! idx = np . random . randint ( 0 , length ) return random_list [ idx ] test_sample_method ( sample_list , random_list , 10000 ) Ahora s\u00ed observamos que cada unon de los n\u00fameros ha sido elegido un n\u00famero similar de veces. Pues bien, ya tenemos el framework montado para escribir una funci\u00f3n distinta a sample_list que resuelva el problema de una forma m\u00e1s eficiente (sin tener que mantener en memoria toda la lista). \u00bfAlguna otra idea de c\u00f3mo resolverlo? Podr\u00edamos leer primero el stream para averiguar el n\u00famero de elementos, generar un n\u00famero aleatorio en el rango de la lista y, posteriormente, volver a leer el stream desde el principio y seleccionar el elemento que se corresponde con el \u00edndice seleccionado. Esta otra opci\u00f3n tiene un punto d\u00e9bil muy claro: debemos de leer el stream 2 veces. Directamente nos saltaremos esta implementaci\u00f3n e iremos con la forma m\u00e1s eficiente: un algoritmo que nos permite hacer esa selecci\u00f3n leyendo una \u00fanica vez el stream y sin almacenar toda la lista en memoria.","title":"\ud83c\uddea\ud83c\uddf8 Reservoir sampling"},{"location":"problems/reservoir-sampling/#reservoir-sampling_1","text":"Todo lo anterior comentado no es m\u00e1s que una introducci\u00f3n larga para llegar a la descripci\u00f3n del algoritmo reservoir sampling . El funcionamiento de este algoritmo se basa en seleccionar aleatoriamente elementos provisionales hasta que termina el stream. Cuando finaliza el stream, el \u00faltimo elemento provisional seleccionado es devuelto, de forma que la probablidad de seleccionar un elemento del stream es ex\u00e1ctamente la misma para todos los elementos. Guardando \u00fanicamente un solo elemento en memoria la complejidad espacial de este algoritmo es \\( \\(\\mathcal{O}(1)\\) \\) y, puesto que solo se leen los elementos una vez, la complejidad temporal es \\( \\(\\mathcal{O}(n)\\) \\) siendo \\(n\\) el n\u00famero de elementos del stream. Formalizemos el problema usando matem\u00e1ticas. Queremos que la probabilidad de elegir un elemento \\( \\(x_i\\) \\) de la lista \\( \\(\\mathbf{x} = {x_1, x_2, \\cdots, x_n}\\) \\) sea \\( \\(P(x_i) = \\dfrac{1}{n}\\) \\) para todo valor de \\( \\(1 \\leq i \\leq n\\) \\) . Sup\u00f3n que comienza el stream y recibes un elemento. Si dejamos pasar ese elemento y el stream finaliza sin darte ning\u00fan elemento m\u00e1s, tendr\u00edamos un problema puesto que nuestro algoritmo no devolver\u00eda ning\u00fan elemento aleatorio de la lista. El primer elemento hay que cogerlo s\u00ed o s\u00ed. Con cogerlo me refiero a guardarlo temporalmente en memoria. Si el stream termina ah\u00ed, tendr\u00edamos que devolver ese elemento sin m\u00e1s. Esto tiene sentido puesto que cuando tenemos un solo elemento en la lista la probabilidad de cogerlo es 1: $$ P_1(x_1) = \\dfrac{1}{n} = \\dfrac{1}{1} = 1 $$. Con \\( \\(P_1\\) \\) indico que hemos le\u00eddo un solo elemento del stream. Si el stream no termina, hay que seguir leyendo elementos y sustituir aleatoriamente el antiguo elemento por uno de los nuevos. Cuando leemos un segundo elemento deber\u00edamos tener: $$ P_2(x_2) = \\dfrac{1}{n} = \\dfrac{1}{2} = 0.5 $$. Es decir, la mitad de las veces sustituir\u00edamos el elemento provisional (el primer elemento) por el segundo. Para realizar esto en Python podemos evaluar la condici\u00f3n np.random.randint(0, 2) == 0 . La funci\u00f3n randint nos devolver\u00e1 o un 0 o un 1 de manera uniforme, por lo que la mitad de las veces ser\u00e1 0. Si se cumple la condici\u00f3n, podremos sustituir el elemento provisional por el nuevo. \\( \\(P_2(x_2) = 0.5\\) \\) , tal y como deber\u00eda de ser. Pero ahora que hemos a\u00f1adido un elemento nuevo \u00bfcu\u00e1l es la probabilidad de acabar eligiendo el primer elemento? Es decir, \u00bfcu\u00e1nto vale \\( \\(P_2(x_1)\\) \\) ? \u00bfSigue siendo \\( \\(P_2(x_1) = P_1(x_1) = 1\\) \\) ? Ovbiamente ya no es 1 puesto que la mitad de las veces ser\u00e1 sustituido por el segundo elemento. La nueva probabilidad de elegir el primer elemento es la probabilidad de elegir el elemento en el paso anterior ( \\( \\(P_1(x_1)\\) \\) ) por la probabilidad de no elegir el segundo elemento ( \\( \\(1 - P_2(x_2)\\) \\) ). Traduciendo a una expresi\u00f3n matem\u00e1tica tenemos que: $$ P_2(x_1) = P_1(x_1) \\cdot (1 - P_2(x_2)) = 1 \\cdot (1 - 0.5) = 0.5 $$. La posible sustituci\u00f3n de \\( \\(x_1\\) \\) cuando se lee el segundo elemento cambia la probabilidad de elegir \\( \\(x_1\\) \\) , y dicha probabilidad coincide con una distribuci\u00f3n uniforme. Podr\u00eda seguir derivando para un tercer elemento, pero directamente voy a escribir la expresi\u00f3n general. \\[ \\begin{aligned} P_n(x_n) &= \\dfrac{1}{n} \\\\ P_n(x_i) &= P_{n-1}(x_i) \\cdot (1 - P_{i+1}(x_{i+1})) \\cdot (1 - P_{i+2}(x_{i+2})) \\cdots (1 - P_n(x_n)) \\end{aligned} \\] para todo valor de \\( \\(i < n\\) \\) . Ahora, partiendo de la expresi\u00f3n general obtengamos la expresi\u00f3n para 3 elementos. \\[ \\begin{aligned} P_3(x_3) &= \\dfrac{1}{3} \\\\ P_3(x_2) &= P_2(x_2) \\cdot (1 - P_3(x_3)) = \\dfrac{1}{2} \\cdot \\left( 1 - \\dfrac{1}{3} \\right) = \\dfrac{1}{2} \\cdot \\dfrac{2}{3} = \\dfrac{2}{6} = \\dfrac{1}{3} \\\\ P_3(x_1) &= P_2(x_1) \\cdot (1 - P_2(x_2)) \\cdot (1 - P_3(x_3)) = \\\\ &= \\dfrac{1}{2} \\cdot \\left(1 - \\dfrac{1}{2}\\right) \\cdot \\left(1 - \\dfrac{1}{3}\\right) = \\dfrac{1}{2} \\cdot \\dfrac{1}{2} \\cdot \\dfrac{2}{3} = \\dfrac{2}{6} = \\dfrac{1}{3} \\end{aligned} \\] Como se observa, \\( \\(P_3(x_1) = P_3(x_2) = P_3(x_3) = \\dfrac{1}{3}\\) \\) , por lo que cumple con los requisitos.","title":"Reservoir sampling"},{"location":"problems/reservoir-sampling/#implementacion","text":"La implementaci\u00f3n es muy sencilla, la puedes encontrar justo debajo. def sample_reservoir ( random_iter ): # Cogemos el primer elemento como elemento provisional. sample = next ( random_iter ) for i , n in enumerate ( random_iter ): # Cambiamos el sample cada vez que leemos un nuevo elemento con # probabilidad 1 / n_elementos_leidos. if np . random . randint ( 0 , i + 1 ) == 0 : sample = n # Devolvemos el \u00faltimo sample seleccionado. return sample sample_reservoir ( iter ( random_list )) Con mi semilla aleatoria me proporciona un -5 . Pintemos el histograma despu\u00e9s de haber seleccionado 10000 elementos. test_sample_method ( sample_list , random_list , 10000 ) Efectivamente, con esta nueva funci\u00f3n tambi\u00e9n obtenemos un histograma propio de una distribuci\u00f3n uniforme. \u00a1Misi\u00f3n cumplida! Puedes encontrar un notebook de Python con el c\u00f3digo en el repositorio. Recuerda que para obtener exactamente los mismos resultados debes de ejecutar el notebook de principio a fin, puesto que la semilla aleatoria se configura al principio. Si ejecutas una celda dos veces har\u00e1 que el resultado de las siguientes no sea exactamente el mismo que el m\u00edo.","title":"Implementaci\u00f3n"},{"location":"tags/","text":"Tags Following is a list of relevant tags: Algorithms \ud83c\uddea\ud83c\uddf8 Reservoir sampling Best practices Do not number steps When to stop using Python notebooks Codeforces \ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function Euler \ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function Math \ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function Notebooks When to stop using Python notebooks Python When to stop using Python notebooks Random \ud83c\uddea\ud83c\uddf8 Reservoir sampling Statistics \ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 1 \ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 2","title":"Tags"},{"location":"tags/#tags","text":"Following is a list of relevant tags:","title":"Tags"},{"location":"tags/#algorithms","text":"\ud83c\uddea\ud83c\uddf8 Reservoir sampling","title":"Algorithms"},{"location":"tags/#best-practices","text":"Do not number steps When to stop using Python notebooks","title":"Best practices"},{"location":"tags/#codeforces","text":"\ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function","title":"Codeforces"},{"location":"tags/#euler","text":"\ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function","title":"Euler"},{"location":"tags/#math","text":"\ud83c\uddea\ud83c\uddf8 Euler Phi/Totient function","title":"Math"},{"location":"tags/#notebooks","text":"When to stop using Python notebooks","title":"Notebooks"},{"location":"tags/#python","text":"When to stop using Python notebooks","title":"Python"},{"location":"tags/#random","text":"\ud83c\uddea\ud83c\uddf8 Reservoir sampling","title":"Random"},{"location":"tags/#statistics","text":"\ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 1 \ud83c\uddea\ud83c\uddf8 Maximum Likelihood Estimation - Parte 2","title":"Statistics"}]}